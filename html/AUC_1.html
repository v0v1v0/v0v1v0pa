<div class="container">

<table style="width: 100%;"><tr>
<td>AUC-package</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Threshold independent performance measures for probabilistic classifiers.
</h2>

<h3>Description</h3>

<p>Summary and plotting functions for threshold independent performance measures for probabilistic classifiers.
</p>


<h3>Details</h3>

<p>This package includes functions to compute the area under the curve (function <code>auc</code>) of selected measures: The area under 
the sensitivity curve (AUSEC) (function <code>sensitivity</code>), the area under the specificity curve
(AUSPC) (function <code>specificity</code>), the area under the accuracy curve (AUACC) (function <code>accuracy</code>), and
the area under the receiver operating characteristic curve (AUROC) (function <code>roc</code>). The curves can also be 
visualized using the function <code>plot</code>. Support for partial areas is provided.
</p>
<p>Auxiliary code in this package is adapted from the <code>ROCR</code> package. The measures available in this package are not available in the 
ROCR package or vice versa (except for the AUROC). As for the AUROC, we adapted the <code>ROCR</code> code to increase computational speed 
(so it can be used more effectively in objective functions). As a result less funtionality is offered (e.g., averaging cross validation runs). 
Please use the <code>ROCR</code> package for that purposes.
</p>


<h3>Author(s)</h3>

<p>Michel Ballings and Dirk Van den Poel, Maintainer: <a href="mailto:Michel.Ballings@UGent.be">Michel.Ballings@UGent.be</a>
</p>


<h3>References</h3>

<p>Ballings, M., Van den Poel, D., Threshold Independent Performance Measures for Probabilistic Classifcation Algorithms, Forthcoming.
</p>


<h3>See Also</h3>

<p><code>sensitivity</code>, <code>specificity</code>, <code>accuracy</code>, <code>roc</code>, <code>auc</code>, <code>plot</code>  
</p>


<h3>Examples</h3>

<pre><code class="language-R">data(churn)

auc(sensitivity(churn$predictions,churn$labels))
auc(specificity(churn$predictions,churn$labels))
auc(accuracy(churn$predictions,churn$labels))
auc(roc(churn$predictions,churn$labels))

plot(sensitivity(churn$predictions,churn$labels))
plot(specificity(churn$predictions,churn$labels))
plot(accuracy(churn$predictions,churn$labels))
plot(roc(churn$predictions,churn$labels))

</code></pre>


</div>