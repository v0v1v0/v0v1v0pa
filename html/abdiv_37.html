<div class="container">

<table style="width: 100%;"><tr>
<td>kullback_leibler_divergence</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Kullback-Leibler divergence</h2>

<h3>Description</h3>

<p>Kullback-Leibler divergence
</p>


<h3>Usage</h3>

<pre><code class="language-R">kullback_leibler_divergence(x, y)
</code></pre>


<h3>Arguments</h3>

<table><tr style="vertical-align: top;">
<td><code>x, y</code></td>
<td>
<p>Numeric vectors representing probabilities</p>
</td>
</tr></table>
<h3>Details</h3>

<p>Kullback-Leibler divergence is a non-symmetric measure of difference between
two probability vectors. In general, KL(x, y) is not equal to KL(y, x).
</p>
<p>Because this measure is defined for probabilities, the vectors x and y are
normalized in the function so they sum to 1.
</p>


<h3>Value</h3>

<p>The Kullback-Leibler divergence between <code>x</code> and <code>y</code>. We
adopt the following conventions if elements of <code>x</code> or <code>y</code> are
zero: <code class="reqn">0 \log (0 / y_i) = 0</code>, <code class="reqn">0 \log (0 / 0) = 0</code>, and
<code class="reqn">x_i \log (x_i / 0) = \infty</code>. As a result, if elements of <code>x</code> are
zero, they do not contribute to the sum. If elements of <code>y</code> are zero
where <code>x</code> is nonzero, the result will be <code>Inf</code>. If either
<code>x</code> or <code>y</code> sum to zero, we are not able to compute the
proportions, and we return <code>NaN</code>.
</p>


</div>