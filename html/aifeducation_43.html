<div class="container">

<table style="width: 100%;"><tr>
<td>TextEmbeddingModel</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Text embedding model</h2>

<h3>Description</h3>

<p>This R6 class stores a text embedding model which can be
used to tokenize, encode, decode, and embed raw texts. The object provides a
unique interface for different text processing methods.
</p>


<h3>Value</h3>

<p>Objects of class <code>TextEmbeddingModel</code> transform raw texts into numerical
representations which can be used for downstream tasks. For this aim objects of this class
allow to tokenize raw texts, to encode tokens to sequences of integers, and to decode sequences
of integers back to tokens.
</p>


<h3>Public fields</h3>

<div class="r6-fields">

<dl>
<dt><code>last_training</code></dt>
<dd>
<p>('list()')<br>
List for storing the history and the results of the last training. This
information will be overwritten if a new training is started.</p>
</dd>
</dl>
</div>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-TextEmbeddingModel-new"><code>TextEmbeddingModel$new()</code></a>
</p>
</li>
<li> <p><a href="#method-TextEmbeddingModel-load_model"><code>TextEmbeddingModel$load_model()</code></a>
</p>
</li>
<li> <p><a href="#method-TextEmbeddingModel-save_model"><code>TextEmbeddingModel$save_model()</code></a>
</p>
</li>
<li> <p><a href="#method-TextEmbeddingModel-encode"><code>TextEmbeddingModel$encode()</code></a>
</p>
</li>
<li> <p><a href="#method-TextEmbeddingModel-decode"><code>TextEmbeddingModel$decode()</code></a>
</p>
</li>
<li> <p><a href="#method-TextEmbeddingModel-get_special_tokens"><code>TextEmbeddingModel$get_special_tokens()</code></a>
</p>
</li>
<li> <p><a href="#method-TextEmbeddingModel-embed"><code>TextEmbeddingModel$embed()</code></a>
</p>
</li>
<li> <p><a href="#method-TextEmbeddingModel-fill_mask"><code>TextEmbeddingModel$fill_mask()</code></a>
</p>
</li>
<li> <p><a href="#method-TextEmbeddingModel-set_publication_info"><code>TextEmbeddingModel$set_publication_info()</code></a>
</p>
</li>
<li> <p><a href="#method-TextEmbeddingModel-get_publication_info"><code>TextEmbeddingModel$get_publication_info()</code></a>
</p>
</li>
<li> <p><a href="#method-TextEmbeddingModel-set_software_license"><code>TextEmbeddingModel$set_software_license()</code></a>
</p>
</li>
<li> <p><a href="#method-TextEmbeddingModel-get_software_license"><code>TextEmbeddingModel$get_software_license()</code></a>
</p>
</li>
<li> <p><a href="#method-TextEmbeddingModel-set_documentation_license"><code>TextEmbeddingModel$set_documentation_license()</code></a>
</p>
</li>
<li> <p><a href="#method-TextEmbeddingModel-get_documentation_license"><code>TextEmbeddingModel$get_documentation_license()</code></a>
</p>
</li>
<li> <p><a href="#method-TextEmbeddingModel-set_model_description"><code>TextEmbeddingModel$set_model_description()</code></a>
</p>
</li>
<li> <p><a href="#method-TextEmbeddingModel-get_model_description"><code>TextEmbeddingModel$get_model_description()</code></a>
</p>
</li>
<li> <p><a href="#method-TextEmbeddingModel-get_model_info"><code>TextEmbeddingModel$get_model_info()</code></a>
</p>
</li>
<li> <p><a href="#method-TextEmbeddingModel-get_package_versions"><code>TextEmbeddingModel$get_package_versions()</code></a>
</p>
</li>
<li> <p><a href="#method-TextEmbeddingModel-get_basic_components"><code>TextEmbeddingModel$get_basic_components()</code></a>
</p>
</li>
<li> <p><a href="#method-TextEmbeddingModel-get_bow_components"><code>TextEmbeddingModel$get_bow_components()</code></a>
</p>
</li>
<li> <p><a href="#method-TextEmbeddingModel-get_transformer_components"><code>TextEmbeddingModel$get_transformer_components()</code></a>
</p>
</li>
<li> <p><a href="#method-TextEmbeddingModel-get_sustainability_data"><code>TextEmbeddingModel$get_sustainability_data()</code></a>
</p>
</li>
<li> <p><a href="#method-TextEmbeddingModel-get_ml_framework"><code>TextEmbeddingModel$get_ml_framework()</code></a>
</p>
</li>
<li> <p><a href="#method-TextEmbeddingModel-clone"><code>TextEmbeddingModel$clone()</code></a>
</p>
</li>
</ul>
<hr>
<a id="method-TextEmbeddingModel-new"></a>



<h4>Method <code>new()</code>
</h4>

<p>Method for creating a new text embedding model
</p>


<h5>Usage</h5>

<div class="r"><pre>TextEmbeddingModel$new(
  model_name = NULL,
  model_label = NULL,
  model_version = NULL,
  model_language = NULL,
  method = NULL,
  ml_framework = aifeducation_config$get_framework()$TextEmbeddingFramework,
  max_length = 0,
  chunks = 1,
  overlap = 0,
  emb_layer_min = "middle",
  emb_layer_max = "2_3_layer",
  emb_pool_type = "average",
  model_dir,
  bow_basic_text_rep,
  bow_n_dim = 10,
  bow_n_cluster = 100,
  bow_max_iter = 500,
  bow_max_iter_cluster = 500,
  bow_cr_criterion = 1e-08,
  bow_learning_rate = 1e-08,
  trace = FALSE
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>model_name</code></dt>
<dd>
<p><code>string</code> containing the name of the new model.</p>
</dd>
<dt><code>model_label</code></dt>
<dd>
<p><code>string</code> containing the label/title of the new model.</p>
</dd>
<dt><code>model_version</code></dt>
<dd>
<p><code>string</code> version of the model.</p>
</dd>
<dt><code>model_language</code></dt>
<dd>
<p><code>string</code> containing the language which the model
represents (e.g., English).</p>
</dd>
<dt><code>method</code></dt>
<dd>
<p><code>string</code> determining the kind of embedding model. Currently
the following models are supported:
<code>method="bert"</code> for Bidirectional Encoder Representations from Transformers (BERT),
<code>method="roberta"</code> for A Robustly Optimized BERT Pretraining Approach (RoBERTa),
<code>method="longformer"</code> for Long-Document Transformer,
<code>method="funnel"</code> for Funnel-Transformer,
<code>method="deberta_v2"</code> for Decoding-enhanced BERT with Disentangled Attention (DeBERTa V2),
<code>method="glove"</code> for
GlobalVector Clusters, and
<code>method="lda"</code> for topic modeling. See
details for more information.</p>
</dd>
<dt><code>ml_framework</code></dt>
<dd>
<p><code>string</code> Framework to use for the model.
<code>ml_framework="tensorflow"</code> for 'tensorflow' and <code>ml_framework="pytorch"</code>
for 'pytorch'. Only relevant for transformer models.</p>
</dd>
<dt><code>max_length</code></dt>
<dd>
<p><code>int</code> determining the maximum length of token
sequences used in transformer models. Not relevant for the other methods.</p>
</dd>
<dt><code>chunks</code></dt>
<dd>
<p><code>int</code> Maximum number of chunks. Only relevant for
transformer models.</p>
</dd>
<dt><code>overlap</code></dt>
<dd>
<p><code>int</code> determining the number of tokens which should be added
at the beginning of the next chunk. Only relevant for BERT models.</p>
</dd>
<dt><code>emb_layer_min</code></dt>
<dd>
<p><code>int</code> or <code>string</code> determining the first layer to be included
in the creation of embeddings. An integer correspondents to the layer number. The first
layer has the number 1. Instead of an integer the following strings are possible:
<code>"start"</code> for the first layer, <code>"middle"</code> for the middle layer,
<code>"2_3_layer"</code> for the layer two-third layer, and <code>"last"</code> for the last layer.</p>
</dd>
<dt><code>emb_layer_max</code></dt>
<dd>
<p><code>int</code> or <code>string</code> determining the last layer to be included
in the creation of embeddings. An integer correspondents to the layer number. The first
layer has the number 1. Instead of an integer the following strings are possible:
<code>"start"</code> for the first layer, <code>"middle"</code> for the middle layer,
<code>"2_3_layer"</code> for the layer two-third layer, and <code>"last"</code> for the last layer.</p>
</dd>
<dt><code>emb_pool_type</code></dt>
<dd>
<p><code>string</code> determining the method for pooling the token embeddings
within each layer. If <code>"cls"</code> only the embedding of the CLS token is used. If
<code>"average"</code> the token embedding of all tokens are averaged (excluding padding tokens).</p>
</dd>
<dt><code>model_dir</code></dt>
<dd>
<p><code>string</code> path to the directory where the
BERT model is stored.</p>
</dd>
<dt><code>bow_basic_text_rep</code></dt>
<dd>
<p>object of class <code>basic_text_rep</code> created via
the function bow_pp_create_basic_text_rep. Only relevant for <code>method="glove_cluster"</code>
and <code>method="lda"</code>.</p>
</dd>
<dt><code>bow_n_dim</code></dt>
<dd>
<p><code>int</code> Number of dimensions of the GlobalVector or
number of topics for LDA.</p>
</dd>
<dt><code>bow_n_cluster</code></dt>
<dd>
<p><code>int</code> Number of clusters created on the basis
of GlobalVectors. Parameter is not relevant for <code>method="lda"</code> and
<code>method="bert"</code></p>
</dd>
<dt><code>bow_max_iter</code></dt>
<dd>
<p><code>int</code> Maximum number of iterations for fitting
GlobalVectors and Topic Models.</p>
</dd>
<dt><code>bow_max_iter_cluster</code></dt>
<dd>
<p><code>int</code> Maximum number of iterations for
fitting cluster if <code>method="glove"</code>.</p>
</dd>
<dt><code>bow_cr_criterion</code></dt>
<dd>
<p><code>double</code> convergence criterion for GlobalVectors.</p>
</dd>
<dt><code>bow_learning_rate</code></dt>
<dd>
<p><code>double</code> initial learning rate for GlobalVectors.</p>
</dd>
<dt><code>trace</code></dt>
<dd>
<p><code>bool</code> <code>TRUE</code> prints information about the progress.
<code>FALSE</code> does not.</p>
</dd>
</dl>
</div>



<h5>Details</h5>


<ul><li>
<p>method: In the case of <code>method="bert"</code>, <code>method="roberta"</code>, and <code>method="longformer"</code>,
a pretrained transformer model
must be supplied via <code>model_dir</code>. For <code>method="glove"</code>
and <code>method="lda"</code> a new model will be created based on the data provided
via <code>bow_basic_text_rep</code>. The original algorithm for GlobalVectors provides
only word embeddings, not text embeddings. To achieve text embeddings the words
are clustered based on their word embeddings with kmeans.
</p>
</li></ul>
<h5>Returns</h5>

<p>Returns an object of class TextEmbeddingModel.
</p>


<hr>
<a id="method-TextEmbeddingModel-load_model"></a>



<h4>Method <code>load_model()</code>
</h4>

<p>Method for loading a transformers model into R.
</p>


<h5>Usage</h5>

<div class="r"><pre>TextEmbeddingModel$load_model(model_dir, ml_framework = "auto")</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>model_dir</code></dt>
<dd>
<p><code>string</code> containing the path to the relevant
model directory.</p>
</dd>
<dt><code>ml_framework</code></dt>
<dd>
<p><code>string</code> Determines the machine learning framework
for using the model. Possible are <code>ml_framework="pytorch"</code> for 'pytorch',
<code>ml_framework="tensorflow"</code> for 'tensorflow', and <code>ml_framework="auto"</code>.</p>
</dd>
</dl>
</div>



<h5>Returns</h5>

<p>Function does not return a value. It is used for loading a saved
transformer model into the R interface.
</p>


<hr>
<a id="method-TextEmbeddingModel-save_model"></a>



<h4>Method <code>save_model()</code>
</h4>

<p>Method for saving a transformer model on disk.Relevant
only for transformer models.
</p>


<h5>Usage</h5>

<div class="r"><pre>TextEmbeddingModel$save_model(model_dir, save_format = "default")</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>model_dir</code></dt>
<dd>
<p><code>string</code> containing the path to the relevant
model directory.</p>
</dd>
<dt><code>save_format</code></dt>
<dd>
<p>Format for saving the model. For 'tensorflow'/'keras' models
<code>"h5"</code> for HDF5.
For 'pytorch' models <code>"safetensors"</code> for 'safetensors' or
<code>"pt"</code> for 'pytorch' via pickle.
Use <code>"default"</code> for the standard format. This is h5 for
'tensorflow'/'keras' models and safetensors for 'pytorch' models.</p>
</dd>
</dl>
</div>



<h5>Returns</h5>

<p>Function does not return a value. It is used for saving a transformer model
to disk.
</p>


<hr>
<a id="method-TextEmbeddingModel-encode"></a>



<h4>Method <code>encode()</code>
</h4>

<p>Method for encoding words of raw texts into integers.
</p>


<h5>Usage</h5>

<div class="r"><pre>TextEmbeddingModel$encode(
  raw_text,
  token_encodings_only = FALSE,
  to_int = TRUE,
  trace = FALSE
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>raw_text</code></dt>
<dd>
<p><code>vector</code> containing the raw texts.</p>
</dd>
<dt><code>token_encodings_only</code></dt>
<dd>
<p><code>bool</code> If <code>TRUE</code>, only the token
encodings are returned. If <code>FALSE</code>, the complete encoding is returned
which is important for BERT models.</p>
</dd>
<dt><code>to_int</code></dt>
<dd>
<p><code>bool</code> If <code>TRUE</code> the integer ids of the tokens are
returned. If <code>FALSE</code> the tokens are returned. Argument only applies
for transformer models and if <code>token_encodings_only==TRUE</code>.</p>
</dd>
<dt><code>trace</code></dt>
<dd>
<p><code>bool</code> If <code>TRUE</code>, information of the progress
is printed. <code>FALSE</code> if not requested.</p>
</dd>
</dl>
</div>



<h5>Returns</h5>

<p><code>list</code> containing the integer sequences of the raw texts with
special tokens.
</p>


<hr>
<a id="method-TextEmbeddingModel-decode"></a>



<h4>Method <code>decode()</code>
</h4>

<p>Method for decoding a sequence of integers into tokens
</p>


<h5>Usage</h5>

<div class="r"><pre>TextEmbeddingModel$decode(int_seqence, to_token = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>int_seqence</code></dt>
<dd>
<p><code>list</code> containing the integer sequences which
should be transformed to tokens or plain text.</p>
</dd>
<dt><code>to_token</code></dt>
<dd>
<p><code>bool</code> If <code>FALSE</code> a plain text is returned.
if <code>TRUE</code> a sequence of tokens is returned. Argument only relevant
if the model is based on a transformer.</p>
</dd>
</dl>
</div>



<h5>Returns</h5>

<p><code>list</code> of token sequences
</p>


<hr>
<a id="method-TextEmbeddingModel-get_special_tokens"></a>



<h4>Method <code>get_special_tokens()</code>
</h4>

<p>Method for receiving the special tokens of the model
</p>


<h5>Usage</h5>

<div class="r"><pre>TextEmbeddingModel$get_special_tokens()</pre></div>



<h5>Returns</h5>

<p>Returns a <code>matrix</code> containing the special tokens in the rows
and their type, token, and id in the columns.
</p>


<hr>
<a id="method-TextEmbeddingModel-embed"></a>



<h4>Method <code>embed()</code>
</h4>

<p>Method for creating text embeddings from raw texts
</p>
<p>In the case of using a GPU and running out of memory reduce the
batch size or restart R and switch to use cpu only via set_config_cpu_only.
</p>


<h5>Usage</h5>

<div class="r"><pre>TextEmbeddingModel$embed(
  raw_text = NULL,
  doc_id = NULL,
  batch_size = 8,
  trace = FALSE
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>raw_text</code></dt>
<dd>
<p><code>vector</code> containing the raw texts.</p>
</dd>
<dt><code>doc_id</code></dt>
<dd>
<p><code>vector</code> containing the corresponding IDs for every text.</p>
</dd>
<dt><code>batch_size</code></dt>
<dd>
<p><code>int</code> determining the maximal size of every batch.</p>
</dd>
<dt><code>trace</code></dt>
<dd>
<p><code>bool</code> <code>TRUE</code>, if information about the progression
should be printed on console.</p>
</dd>
</dl>
</div>



<h5>Returns</h5>

<p>Method returns a R6 object of class EmbeddedText. This object
contains the embeddings as a <code>data.frame</code> and information about the
model creating the embeddings.
</p>


<hr>
<a id="method-TextEmbeddingModel-fill_mask"></a>



<h4>Method <code>fill_mask()</code>
</h4>

<p>Method for calculating tokens behind mask tokens.
</p>


<h5>Usage</h5>

<div class="r"><pre>TextEmbeddingModel$fill_mask(text, n_solutions = 5)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>text</code></dt>
<dd>
<p><code>string</code> Text containing mask tokens.</p>
</dd>
<dt><code>n_solutions</code></dt>
<dd>
<p><code>int</code> Number estimated tokens for every mask.</p>
</dd>
</dl>
</div>



<h5>Returns</h5>

<p>Returns a <code>list</code> containing a <code>data.frame</code> for every
mask. The <code>data.frame</code> contains the solutions in the rows and reports
the score, token id, and token string in the columns.
</p>


<hr>
<a id="method-TextEmbeddingModel-set_publication_info"></a>



<h4>Method <code>set_publication_info()</code>
</h4>

<p>Method for setting the bibliographic information of the model.
</p>


<h5>Usage</h5>

<div class="r"><pre>TextEmbeddingModel$set_publication_info(type, authors, citation, url = NULL)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>type</code></dt>
<dd>
<p><code>string</code> Type of information which should be changed/added.
<code>type="developer"</code>, and <code>type="modifier"</code> are possible.</p>
</dd>
<dt><code>authors</code></dt>
<dd>
<p>List of people.</p>
</dd>
<dt><code>citation</code></dt>
<dd>
<p><code>string</code> Citation in free text.</p>
</dd>
<dt><code>url</code></dt>
<dd>
<p><code>string</code> Corresponding URL if applicable.</p>
</dd>
</dl>
</div>



<h5>Returns</h5>

<p>Function does not return a value. It is used to set the private
members for publication information of the model.
</p>


<hr>
<a id="method-TextEmbeddingModel-get_publication_info"></a>



<h4>Method <code>get_publication_info()</code>
</h4>

<p>Method for getting the bibliographic information of the model.
</p>


<h5>Usage</h5>

<div class="r"><pre>TextEmbeddingModel$get_publication_info()</pre></div>



<h5>Returns</h5>

<p><code>list</code> of bibliographic information.
</p>


<hr>
<a id="method-TextEmbeddingModel-set_software_license"></a>



<h4>Method <code>set_software_license()</code>
</h4>

<p>Method for setting the license of the model
</p>


<h5>Usage</h5>

<div class="r"><pre>TextEmbeddingModel$set_software_license(license = "GPL-3")</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>license</code></dt>
<dd>
<p><code>string</code> containing the abbreviation of the license or
the license text.</p>
</dd>
</dl>
</div>



<h5>Returns</h5>

<p>Function does not return a value. It is used for setting the private
member for the software license of the model.
</p>


<hr>
<a id="method-TextEmbeddingModel-get_software_license"></a>



<h4>Method <code>get_software_license()</code>
</h4>

<p>Method for requesting the license of the model
</p>


<h5>Usage</h5>

<div class="r"><pre>TextEmbeddingModel$get_software_license()</pre></div>



<h5>Returns</h5>

<p><code>string</code> License of the model
</p>


<hr>
<a id="method-TextEmbeddingModel-set_documentation_license"></a>



<h4>Method <code>set_documentation_license()</code>
</h4>

<p>Method for setting the license of models' documentation.
</p>


<h5>Usage</h5>

<div class="r"><pre>TextEmbeddingModel$set_documentation_license(license = "CC BY-SA")</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>license</code></dt>
<dd>
<p><code>string</code> containing the abbreviation of the license or
the license text.</p>
</dd>
</dl>
</div>



<h5>Returns</h5>

<p>Function does not return a value. It is used to set the private member for the
documentation license of the model.
</p>


<hr>
<a id="method-TextEmbeddingModel-get_documentation_license"></a>



<h4>Method <code>get_documentation_license()</code>
</h4>

<p>Method for getting the license of the models' documentation.
</p>


<h5>Usage</h5>

<div class="r"><pre>TextEmbeddingModel$get_documentation_license()</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>license</code></dt>
<dd>
<p><code>string</code> containing the abbreviation of the license or
the license text.</p>
</dd>
</dl>
</div>


<hr>
<a id="method-TextEmbeddingModel-set_model_description"></a>



<h4>Method <code>set_model_description()</code>
</h4>

<p>Method for setting a description of the model
</p>


<h5>Usage</h5>

<div class="r"><pre>TextEmbeddingModel$set_model_description(
  eng = NULL,
  native = NULL,
  abstract_eng = NULL,
  abstract_native = NULL,
  keywords_eng = NULL,
  keywords_native = NULL
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>eng</code></dt>
<dd>
<p><code>string</code> A text describing the training of the classifier,
its theoretical and empirical background, and the different output labels
in English.</p>
</dd>
<dt><code>native</code></dt>
<dd>
<p><code>string</code> A text describing the training of the classifier,
its theoretical and empirical background, and the different output labels
in the native language of the model.</p>
</dd>
<dt><code>abstract_eng</code></dt>
<dd>
<p><code>string</code> A text providing a summary of the description
in English.</p>
</dd>
<dt><code>abstract_native</code></dt>
<dd>
<p><code>string</code> A text providing a summary of the description
in the native language of the classifier.</p>
</dd>
<dt><code>keywords_eng</code></dt>
<dd>
<p><code>vector</code> of keywords in English.</p>
</dd>
<dt><code>keywords_native</code></dt>
<dd>
<p><code>vector</code> of keywords in the native language of the classifier.</p>
</dd>
</dl>
</div>



<h5>Returns</h5>

<p>Function does not return a value. It is used to set the private members for the
description of the model.
</p>


<hr>
<a id="method-TextEmbeddingModel-get_model_description"></a>



<h4>Method <code>get_model_description()</code>
</h4>

<p>Method for requesting the model description.
</p>


<h5>Usage</h5>

<div class="r"><pre>TextEmbeddingModel$get_model_description()</pre></div>



<h5>Returns</h5>

<p><code>list</code> with the description of the model in English
and the native language.
</p>


<hr>
<a id="method-TextEmbeddingModel-get_model_info"></a>



<h4>Method <code>get_model_info()</code>
</h4>

<p>Method for requesting the model information
</p>


<h5>Usage</h5>

<div class="r"><pre>TextEmbeddingModel$get_model_info()</pre></div>



<h5>Returns</h5>

<p><code>list</code> of all relevant model information
</p>


<hr>
<a id="method-TextEmbeddingModel-get_package_versions"></a>



<h4>Method <code>get_package_versions()</code>
</h4>

<p>Method for requesting a summary of the R and python packages'
versions used for creating the classifier.
</p>


<h5>Usage</h5>

<div class="r"><pre>TextEmbeddingModel$get_package_versions()</pre></div>



<h5>Returns</h5>

<p>Returns a <code>list</code> containing the versions of the relevant
R and python packages.
</p>


<hr>
<a id="method-TextEmbeddingModel-get_basic_components"></a>



<h4>Method <code>get_basic_components()</code>
</h4>

<p>Method for requesting the part of interface's configuration that is
necessary for all models.
</p>


<h5>Usage</h5>

<div class="r"><pre>TextEmbeddingModel$get_basic_components()</pre></div>



<h5>Returns</h5>

<p>Returns a <code>list</code>.
</p>


<hr>
<a id="method-TextEmbeddingModel-get_bow_components"></a>



<h4>Method <code>get_bow_components()</code>
</h4>

<p>Method for requesting the part of interface's configuration that is
necessary bag-of-words models.
</p>


<h5>Usage</h5>

<div class="r"><pre>TextEmbeddingModel$get_bow_components()</pre></div>



<h5>Returns</h5>

<p>Returns a <code>list</code>.
</p>


<hr>
<a id="method-TextEmbeddingModel-get_transformer_components"></a>



<h4>Method <code>get_transformer_components()</code>
</h4>

<p>Method for requesting the part of interface's configuration that is
necessary for transformer models.
</p>


<h5>Usage</h5>

<div class="r"><pre>TextEmbeddingModel$get_transformer_components()</pre></div>



<h5>Returns</h5>

<p>Returns a <code>list</code>.
</p>


<hr>
<a id="method-TextEmbeddingModel-get_sustainability_data"></a>



<h4>Method <code>get_sustainability_data()</code>
</h4>

<p>Method for requesting a log of tracked energy consumption
during training and an estimate of the resulting CO2 equivalents in kg.
</p>


<h5>Usage</h5>

<div class="r"><pre>TextEmbeddingModel$get_sustainability_data()</pre></div>



<h5>Returns</h5>

<p>Returns a <code>matrix</code> containing the tracked energy consumption,
CO2 equivalents in kg, information on the tracker used, and technical
information on the training infrastructure for every training run.
</p>


<hr>
<a id="method-TextEmbeddingModel-get_ml_framework"></a>



<h4>Method <code>get_ml_framework()</code>
</h4>

<p>Method for requesting the machine learning framework used
for the classifier.
</p>


<h5>Usage</h5>

<div class="r"><pre>TextEmbeddingModel$get_ml_framework()</pre></div>



<h5>Returns</h5>

<p>Returns a <code>string</code> describing the machine learning framework used
for the classifier
</p>


<hr>
<a id="method-TextEmbeddingModel-clone"></a>



<h4>Method <code>clone()</code>
</h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>TextEmbeddingModel$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt>
<dd>
<p>Whether to make a deep clone.</p>
</dd>
</dl>
</div>




<h3>See Also</h3>

<p>Other Text Embedding: 
<code>EmbeddedText</code>,
<code>combine_embeddings()</code>
</p>


</div>