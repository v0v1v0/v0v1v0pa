<div class="container">

<table style="width: 100%;"><tr>
<td>adaHuber.lasso</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Regularized Adaptive Huber Regression</h2>

<h3>Description</h3>

<p>Sparse regularized Huber regression models in high dimensions with <code class="reqn">\ell_1</code> (lasso) penalty. The function implements a localized majorize-minimize algorithm with a gradient-based method.
</p>


<h3>Usage</h3>

<pre><code class="language-R">adaHuber.lasso(
  X,
  Y,
  lambda = 0.5,
  tau = 0,
  phi0 = 0.01,
  gamma = 1.2,
  epsilon = 0.001,
  iteMax = 500
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>
<p>A <code class="reqn">n</code> by <code class="reqn">p</code> design matrix. Each row is a vector of observation with <code class="reqn">p</code> covariates.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Y</code></td>
<td>
<p>An <code class="reqn">n</code>-dimensional response vector.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda</code></td>
<td>
<p>(<strong>optional</strong>) Regularization parameter. Must be positive. Default is 0.5.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tau</code></td>
<td>
<p>(<strong>optional</strong>) The robustness parameter. If not specified or the input value is non-positive, a tuning-free principle is applied. Default is 0 (hence, tuning-free).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>phi0</code></td>
<td>
<p>(<strong>optional</strong>) The initial quadratic coefficient parameter in the local adaptive majorize-minimize algorithm. Default is 0.01.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>gamma</code></td>
<td>
<p>(<strong>optional</strong>) The adaptive search parameter (greater than 1) in the local adaptive majorize-minimize algorithm. Default is 1.2.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>epsilon</code></td>
<td>
<p>(<strong>optional</strong>) Tolerance level of the gradient-based algorithm. The iteration will stop when the maximum magnitude of all the elements of the gradient is less than <code>tol</code>. Default is 1e-03.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>iteMax</code></td>
<td>
<p>(<strong>optional</strong>) Maximum number of iterations. Default is 500.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>An object containing the following items will be returned:
</p>

<dl>
<dt><code>coef</code></dt>
<dd>
<p>A <code class="reqn">(p + 1)</code> vector of estimated sparse regression coefficients, including the intercept.</p>
</dd>
<dt><code>tau</code></dt>
<dd>
<p>The robustification parameter calibrated by the tuning-free principle (if the input is non-positive).</p>
</dd>
<dt><code>iteration</code></dt>
<dd>
<p>Number of iterations until convergence.</p>
</dd>
<dt><code>phi</code></dt>
<dd>
<p>The quadratic coefficient parameter in the local adaptive majorize-minimize algorithm.</p>
</dd>
</dl>
<h3>References</h3>

<p>Pan, X., Sun, Q. and Zhou, W.-X. (2021). Iteratively reweighted l1-penalized robust regression. Electron. J. Stat., 15, 3287-3348.
</p>
<p>Sun, Q., Zhou, W.-X. and Fan, J. (2020). Adaptive Huber regression. J. Amer. Statist. Assoc., 115 254-265.
</p>
<p>Wang, L., Zheng, C., Zhou, W. and Zhou, W.-X. (2021). A new principle for tuning-free Huber regression. Stat. Sinica, 31, 2153-2177.
</p>


<h3>See Also</h3>

<p>See <code>adaHuber.cv.lasso</code> for regularized adaptive Huber regression with cross-validation.
</p>


<h3>Examples</h3>

<pre><code class="language-R">n = 200; p = 500; s = 10
beta = c(rep(1.5, s + 1), rep(0, p - s))
X = matrix(rnorm(n * p), n, p)
err = rt(n, 2)
Y = cbind(rep(1, n), X) %*% beta + err 

fit.lasso = adaHuber.lasso(X, Y, lambda = 0.5)
beta.lasso = fit.lasso$coef
</code></pre>


</div>