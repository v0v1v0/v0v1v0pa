<div class="container">

<table style="width: 100%;"><tr>
<td>is.redundant</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Find Redundant Rules</h2>

<h3>Description</h3>

<p>Provides the generic function <code>is.redundant()</code> and the method to find
redundant rules based on any interest measure.
</p>


<h3>Usage</h3>

<pre><code class="language-R">is.redundant(x, ...)

## S4 method for signature 'rules'
is.redundant(
  x,
  measure = "confidence",
  confint = FALSE,
  level = 0.95,
  smoothCounts = 1,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>a set of rules.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>additional arguments are passed on to
<code>interestMeasure()</code>, or, for <code>confint = TRUE</code> to
<code>confint()</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>measure</code></td>
<td>
<p>measure used to check for redundancy.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>confint</code></td>
<td>
<p>should confidence intervals be used to the redundancy check?</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>level</code></td>
<td>
<p>confidence level for the confidence interval. Only used when
<code>confint = TRUE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>smoothCounts</code></td>
<td>
<p>adds a "pseudo count" to each count in the used
contingency table. This implements addaptive smoothing (Laplace smoothing)
for counts and avoids zero counts.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p><b>Simple improvement-based redundancy:</b> (<code>confint = FALSE</code>) A rule
can be defined as redundant if a more general rules with the same or a
higher confidence exists. That is, a more specific rule is redundant if it
is only equally or even less predictive than a more general rule. A rule is
more general if it has the same RHS but one or more items removed from the
LHS. Formally, a rule <code class="reqn">X \Rightarrow Y</code> is redundant if
</p>
<p style="text-align: center;"><code class="reqn">\exists X' \subset X \quad conf(X' \Rightarrow Y) \ge conf(X
\Rightarrow Y).</code>
</p>

<p>This is equivalent to a negative or zero <em>improvement</em> as defined by
Bayardo et al. (2000).
</p>
<p>The idea of improvement can be extended other measures besides confidence.
Any other measure available for function <code>interestMeasure()</code> (e.g.,
lift or the odds ratio) can be specified in <code>measure</code>.
</p>
<p><b>Confidence interval-based redundancy:</b> (<code>confint = TRUE</code>) Li et
al (2014) propose to use the confidence interval (CI) of the odds ratio (OR)
of rules to define redundancy. A more specific rule is redundant if it does
not provide a significantly higher OR than any more general rule. Using
confidence intervals as error bounds, a more specific rule is
defined as redundant if its OR CI overlaps with the CI of any more general
rule. This type of redundancy detection removes more rules
than improvement since it takes differences in counts due to randomness in
the dataset into account.
</p>
<p>The odds ratio and the CI are based on counts which can be zero and which
leads to numerical problems. In addition to the method described by Li et al
(2014), we use additive smoothing (Laplace smoothing) to alleviate this
problem. The default setting adds 1 to each count (see
<code>confint()</code>). A different pseudocount (smoothing parameter) can be
defined using the additional parameter <code>smoothCounts</code>. Smoothing can be
disabled using <code>smoothCounts = 0</code>.
</p>
<p><strong>Warning:</strong> This approach of redundancy checking is flawed since rules with
non-overlapping CIs are
non-redundant (same result as for a 2-sample t-test), but overlapping CIs do
not automatically mean that there is no significant difference between the
two measures which leads to a higher type II error. At the same time,
multiple comparisons are performed leading to an increased type I error. If
we are more worried about missing important rules, then the type II error
is more concerning.
</p>
<p>Confidence interval-based redundancy checks can also be used for other
measures with a confidence interval like confidence (see
<code>confint()</code>).
</p>


<h3>Value</h3>

<p>returns a logical vector indicating which rules are redundant.
</p>


<h3>Author(s)</h3>

<p>Michael Hahsler and Christian Buchta
</p>


<h3>References</h3>

<p>Bayardo, R. , R. Agrawal, and D. Gunopulos (2000).
Constraint-based rule mining in large, dense databases. <em>Data Mining
and Knowledge Discovery,</em> 4(2/3):217–240.
</p>
<p>Li, J., Jixue Liu, Hannu Toivonen, Kenji Satou, Youqiang Sun, and Bingyu Sun
(2014). Discovering statistically non-redundant subgroups. Knowledge-Based
Systems. 67 (September, 2014), 315–327.
<a href="https://doi.org/10.1016/j.knosys.2014.04.030">doi:10.1016/j.knosys.2014.04.030</a>
</p>


<h3>See Also</h3>

<p>Other postprocessing: 
<code>is.closed()</code>,
<code>is.generator()</code>,
<code>is.maximal()</code>,
<code>is.significant()</code>,
<code>is.superset()</code>
</p>
<p>Other associations functions: 
<code>abbreviate()</code>,
<code>associations-class</code>,
<code>c()</code>,
<code>duplicated()</code>,
<code>extract</code>,
<code>inspect()</code>,
<code>is.closed()</code>,
<code>is.generator()</code>,
<code>is.maximal()</code>,
<code>is.significant()</code>,
<code>is.superset()</code>,
<code>itemsets-class</code>,
<code>match()</code>,
<code>rules-class</code>,
<code>sample()</code>,
<code>sets</code>,
<code>size()</code>,
<code>sort()</code>,
<code>unique()</code>
</p>
<p>Other interest measures: 
<code>confint()</code>,
<code>coverage()</code>,
<code>interestMeasure()</code>,
<code>is.significant()</code>,
<code>support()</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">
data("Income")

## mine some rules with the consequent "language in home=english"
rules &lt;- apriori(Income, parameter = list(support = 0.5),
  appearance = list(rhs = "language in home=english"))

## for better comparison we add Bayado's improvement and sort by improvement
quality(rules)$improvement &lt;- interestMeasure(rules, measure = "improvement")
rules &lt;- sort(rules, by = "improvement")
inspect(rules)
is.redundant(rules)

## find non-redundant rules using improvement of confidence
## Note: a few rules have a very small improvement over the rule {} =&gt; {language in home=english}
rules_non_redundant &lt;- rules[!is.redundant(rules)]
inspect(rules_non_redundant)

## use non-overlapping confidence intervals for the confidence measure instead
## Note: fewer rules have a significantly higher confidence
inspect(rules[!is.redundant(rules, measure = "confidence",
  confint = TRUE, level = 0.95)])

## find non-redundant rules using improvement of the odds ratio.
quality(rules)$oddsRatio &lt;-  interestMeasure(rules, measure = "oddsRatio", smoothCounts = .5)
inspect(rules[!is.redundant(rules, measure = "oddsRatio")])

## use the confidence interval for the odds ratio.
## We see that no rule has a significantly better odds ratio than the most general rule.
inspect(rules[!is.redundant(rules, measure = "oddsRatio",
  confint = TRUE, level = 0.95)])

##  use the confidence interval for lift
inspect(rules[!is.redundant(rules, measure = "lift",
  confint = TRUE, level = 0.95)])

</code></pre>


</div>