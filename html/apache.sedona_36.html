<div class="container">

<table style="width: 100%;"><tr>
<td>spark_write_geojson</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Write geospatial data from a Spark DataFrame.</h2>

<h3>Description</h3>

<p>Functions to write geospatial data into a variety of formats from Spark DataFrames.
</p>

<ul>
<li> <p><code>spark_write_geojson</code>: to GeoJSON
</p>
</li>
<li> <p><code>spark_write_geoparquet</code>: to GeoParquet
</p>
</li>
<li> <p><code>spark_write_raster</code>: to raster tiles after using RS output functions (<code>RS_AsXXX</code>)
</p>
</li>
</ul>
<h3>Usage</h3>

<pre><code class="language-R">spark_write_geojson(
  x,
  path,
  mode = NULL,
  options = list(),
  partition_by = NULL,
  ...
)

spark_write_geoparquet(
  x,
  path,
  mode = NULL,
  options = list(),
  partition_by = NULL,
  ...
)

spark_write_raster(
  x,
  path,
  mode = NULL,
  options = list(),
  partition_by = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>A Spark DataFrame or dplyr operation</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>path</code></td>
<td>
<p>The path to the file. Needs to be accessible from the cluster.
Supports the ‘<span class="samp">⁠"hdfs://"⁠</span>’, ‘<span class="samp">⁠"s3a://"⁠</span>’ and ‘<span class="samp">⁠"file://"⁠</span>’ protocols.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mode</code></td>
<td>
<p>A <code>character</code> element. Specifies the behavior when data or
table already exists. Supported values include: 'error', 'append', 'overwrite' and
ignore. Notice that 'overwrite' will also change the column structure.
</p>
<p>For more details see also <a href="https://spark.apache.org/docs/latest/sql-programming-guide.html">https://spark.apache.org/docs/latest/sql-programming-guide.html</a>
for your version of Spark.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>options</code></td>
<td>
<p>A list of strings with additional options.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>partition_by</code></td>
<td>
<p>A <code>character</code> vector. Partitions the output by the given columns on the file system.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Optional arguments; currently unused.</p>
</td>
</tr>
</table>
<h3>See Also</h3>

<p>Other Sedona DF data interface functions: 
<code>spark_read_shapefile()</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">library(sparklyr)
library(apache.sedona)

sc &lt;- spark_connect(master = "spark://HOST:PORT")

if (!inherits(sc, "test_connection")) {
  tbl &lt;- dplyr::tbl(
    sc,
    dplyr::sql("SELECT ST_GeomFromText('POINT(-71.064544 42.28787)') AS `pt`")
  )
  spark_write_geojson(
    tbl %&gt;% dplyr::mutate(id = 1),
    output_location = "/tmp/pts.geojson"
  )
}

</code></pre>


</div>