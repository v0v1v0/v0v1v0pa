<div class="container">

<table style="width: 100%;"><tr>
<td>AutoScore_testing</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>AutoScore STEP(v): Evaluate the final score with ROC analysis (AutoScore Module 6)</h2>

<h3>Description</h3>

<p>AutoScore STEP(v): Evaluate the final score with ROC analysis (AutoScore Module 6)
</p>


<h3>Usage</h3>

<pre><code class="language-R">AutoScore_testing(
  test_set,
  final_variables,
  cut_vec,
  scoring_table,
  threshold = "best",
  with_label = TRUE,
  metrics_ci = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>test_set</code></td>
<td>
<p>A processed <code>data.frame</code> that contains data for testing purpose. This <code>data.frame</code> should have same format as
<code>train_set</code> (same variable names and outcomes)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>final_variables</code></td>
<td>
<p>A vector containing the list of selected variables, selected from Step(ii) <code>AutoScore_parsimony</code>. Run <code>vignette("Guide_book", package = "AutoScore")</code> to see the guidebook or vignette.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cut_vec</code></td>
<td>
<p>Generated from STEP(iii) <code>AutoScore_weighting</code>.Please follow the guidebook</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>scoring_table</code></td>
<td>
<p>The final scoring table after fine-tuning, generated from STEP(iv) <code>AutoScore_fine_tuning</code>.Please follow the guidebook</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>threshold</code></td>
<td>
<p>Score threshold for the ROC analysis to generate sensitivity, specificity, etc. If set to "best", the optimal threshold will be calculated (Default:"best").</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>with_label</code></td>
<td>
<p>Set to TRUE if there are labels in the test_set and performance will be evaluated accordingly (Default:TRUE).
Set it to "FALSE" if there are not "label" in the "test_set" and the final predicted scores will be the output without performance evaluation.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>metrics_ci</code></td>
<td>
<p>whether to calculate confidence interval for the metrics of sensitivity, specificity, etc.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>A data frame with predicted score and the outcome for downstream visualization.
</p>


<h3>References</h3>


<ul><li>
<p>Xie F, Chakraborty B, Ong MEH, Goldstein BA, Liu N. AutoScore: A Machine Learning-Based Automatic Clinical Score Generator and
Its Application to Mortality Prediction Using Electronic Health Records. JMIR Medical Informatics 2020;8(10):e21798
</p>
</li></ul>
<h3>See Also</h3>

<p><code>AutoScore_rank</code>, <code>AutoScore_parsimony</code>, <code>AutoScore_weighting</code>, <code>AutoScore_fine_tuning</code>, <code>print_roc_performance</code>, Run <code>vignette("Guide_book", package = "AutoScore")</code> to see the guidebook or vignette.
</p>


<h3>Examples</h3>

<pre><code class="language-R">## Please see the guidebook or vignettes
</code></pre>


</div>