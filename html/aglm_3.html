<div class="container">

<table style="width: 100%;"><tr>
<td>aglm</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Fit an AGLM model with no cross-validation</h2>

<h3>Description</h3>

<p>A basic fitting function with given <code class="reqn">\alpha</code> and <code class="reqn">\lambda</code> (s).
See aglm-package for more details on <code class="reqn">\alpha</code> and <code class="reqn">\lambda</code>.
</p>


<h3>Usage</h3>

<pre><code class="language-R">aglm(
  x,
  y,
  qualitative_vars_UD_only = NULL,
  qualitative_vars_both = NULL,
  qualitative_vars_OD_only = NULL,
  quantitative_vars = NULL,
  use_LVar = FALSE,
  extrapolation = "default",
  add_linear_columns = TRUE,
  add_OD_columns_of_qualitatives = TRUE,
  add_interaction_columns = FALSE,
  OD_type_of_quantitatives = "C",
  nbin.max = NULL,
  bins_list = NULL,
  bins_names = NULL,
  family = c("gaussian", "binomial", "poisson"),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>A design matrix.
Usually a <code>data.frame</code> object is expected, but a <code>matrix</code> object is fine if all columns are of a same class.
Each column may have one of the following classes, and <code>aglm</code> will automatically determine how to handle it:
</p>

<ul>
<li> <p><code>numeric</code>: interpreted as a quantitative variable. <code>aglm</code> performs discretization by binning, and creates dummy variables suitable for ordered values (named O-dummies/L-variables).
</p>
</li>
<li> <p><code>factor</code> (unordered) or <code>logical</code> : interpreted as a qualitative variable without order. <code>aglm</code> creates dummy variables suitable for unordered values (named U-dummies).
</p>
</li>
<li> <p><code>ordered</code>: interpreted as a qualitative variable with order. <code>aglm</code> creates both O-dummies and U-dummies.
</p>
</li>
</ul>
<p>These dummy variables are added to <code>x</code> and form a larger matrix, which is used internally as an actual design matrix.
See <a href="https://www.institutdesactuaires.com/global/gene/link.php?doc_id=16273&amp;fg=1">our paper</a> for more details on O-dummies, U-dummies, and L-variables.
</p>
<p>If you need to change the default behavior, use the following options: <code>qualitative_vars_UD_only</code>, <code>qualitative_vars_both</code>, <code>qualitative_vars_OD_only</code>, and <code>quantitative_vars</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>A response variable.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>qualitative_vars_UD_only</code></td>
<td>
<p>Used to change the default behavior of <code>aglm</code> for given variables.
Variables specified by this parameter are considered as qualitative variables and only U-dummies are created as auxiliary columns.
This parameter may have one of the following classes:
</p>

<ul>
<li> <p><code>integer</code>: specifying variables by index.
</p>
</li>
<li> <p><code>character</code>: specifying variables by name.
</p>
</li>
</ul>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>qualitative_vars_both</code></td>
<td>
<p>Same as <code>qualitative_vars_UD_only</code>, except that both O-dummies and U-dummies are created for specified variables.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>qualitative_vars_OD_only</code></td>
<td>
<p>Same as <code>qualitative_vars_UD_only</code>, except that both only O-dummies are created for specified variables.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>quantitative_vars</code></td>
<td>
<p>Same as <code>qualitative_vars_UD_only</code>, except that specified variables are considered as quantitative variables.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>use_LVar</code></td>
<td>
<p>Set to use L-variables.
By default, <code>aglm</code> uses O-dummies as the representation of a quantitative variable.
If <code>use_LVar=TRUE</code>, L-variables are used instead.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>extrapolation</code></td>
<td>
<p>Used to control values of linear combination for quantitative variables, outside where the data exists.
By default, values of a linear combination outside the data is extended based on the slope of the edges of the region where the data exists.
You can set <code>extrapolation="flat"</code> to get constant values outside the data instead.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>add_linear_columns</code></td>
<td>
<p>By default, for quantitative variables, <code>aglm</code> expands them by adding dummies and the original columns, i.e. the linear effects, are remained in the resulting model.
You can set <code>add_linear_columns=FALSE</code> to drop linear effects.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>add_OD_columns_of_qualitatives</code></td>
<td>
<p>Set to <code>FALSE</code> if you do not want to use O-dummies for qualitative variables with order (usually, columns with <code>ordered</code> class).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>add_interaction_columns</code></td>
<td>
<p>If this parameter is set to <code>TRUE</code>, <code>aglm</code> creates an additional auxiliary variable <code>x_i * x_j</code> for each pair <code style="white-space: pre;">⁠(x_i, x_j)⁠</code> of variables.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>OD_type_of_quantitatives</code></td>
<td>
<p>Used to control the shape of linear combinations obtained by O-dummies for quantitative variables (deprecated).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nbin.max</code></td>
<td>
<p>An integer representing the maximum number of bins when <code>aglm</code> perform binning for quantitative variables.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>bins_list</code></td>
<td>
<p>Used to set custom bins for variables with O-dummies.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>bins_names</code></td>
<td>
<p>Used to set custom bins for variables with O-dummies.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>family</code></td>
<td>
<p>A <code>family</code> object or a string representing the type of the error distribution.
Currently <code>aglm</code> supports <code>gaussian</code>, <code>binomial</code>, and <code>poisson</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Other arguments are passed directly when calling <code>glmnet()</code>.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>A model object fitted to the data.
Functions such as <code>predict</code> and <code>plot</code> can be applied to the returned object.
See AccurateGLM-class for more details.
</p>


<h3>Author(s)</h3>


<ul>
<li>
<p> Kenji Kondo,
</p>
</li>
<li>
<p> Kazuhisa Takahashi and Hikari Banno (worked on L-Variable related features)
</p>
</li>
</ul>
<h3>References</h3>

<p>Suguru Fujita, Toyoto Tanaka, Kenji Kondo and Hirokazu Iwasawa. (2020)
<em>AGLM: A Hybrid Modeling Method of GLM and Data Science Techniques</em>, <br><a href="https://www.institutdesactuaires.com/global/gene/link.php?doc_id=16273&amp;fg=1">https://www.institutdesactuaires.com/global/gene/link.php?doc_id=16273&amp;fg=1</a> <br><em>Actuarial Colloquium Paris 2020</em>
</p>


<h3>Examples</h3>

<pre><code class="language-R">
#################### Gaussian case ####################

library(MASS) # For Boston
library(aglm)

## Read data
xy &lt;- Boston # xy is a data.frame to be processed.
colnames(xy)[ncol(xy)] &lt;- "y" # Let medv be the objective variable, y.

## Split data into train and test
n &lt;- nrow(xy) # Sample size.
set.seed(2018) # For reproducibility.
test.id &lt;- sample(n, round(n/4)) # ID numbders for test data.
test &lt;- xy[test.id,] # test is the data.frame for testing.
train &lt;- xy[-test.id,] # train is the data.frame for training.
x &lt;- train[-ncol(xy)]
y &lt;- train$y
newx &lt;- test[-ncol(xy)]
y_true &lt;- test$y

## Fit the model
model &lt;- aglm(x, y)  # alpha=1 (the default value)

## Predict for various alpha and lambda
lambda &lt;- 0.1
y_pred &lt;- predict(model, newx=newx, s=lambda)
rmse &lt;- sqrt(mean((y_true - y_pred)^2))
cat(sprintf("RMSE for lambda=%.2f: %.5f \n\n", lambda, rmse))

lambda &lt;- 1.0
y_pred &lt;- predict(model, newx=newx, s=lambda)
rmse &lt;- sqrt(mean((y_true - y_pred)^2))
cat(sprintf("RMSE for lambda=%.2f: %.5f \n\n", lambda, rmse))

alpha &lt;- 0
model &lt;- aglm(x, y, alpha=alpha)

lambda &lt;- 0.1
y_pred &lt;- predict(model, newx=newx, s=lambda)
rmse &lt;- sqrt(mean((y_true - y_pred)^2))
cat(sprintf("RMSE for alpha=%.2f and lambda=%.2f: %.5f \n\n", alpha, lambda, rmse))

#################### Binomial case ####################

library(aglm)
library(faraway)

## Read data
xy &lt;- nes96

## Split data into train and test
n &lt;- nrow(xy) # Sample size.
set.seed(2018) # For reproducibility.
test.id &lt;- sample(n, round(n/5)) # ID numbders for test data.
test &lt;- xy[test.id,] # test is the data.frame for testing.
train &lt;- xy[-test.id,] # train is the data.frame for training.
x &lt;- train[, c("popul", "TVnews", "selfLR", "ClinLR", "DoleLR", "PID", "age", "educ", "income")]
y &lt;- train$vote
newx &lt;- test[, c("popul", "TVnews", "selfLR", "ClinLR", "DoleLR", "PID", "age", "educ", "income")]

## Fit the model
model &lt;- aglm(x, y, family="binomial")

## Make the confusion matrix
lambda &lt;- 0.1
y_true &lt;- test$vote
y_pred &lt;- levels(y_true)[as.integer(predict(model, newx, s=lambda, type="class"))]

print(table(y_true, y_pred))

#################### use_LVar and extrapolation ####################

library(MASS) # For Boston
library(aglm)

## Randomly created train and test data
set.seed(2021)
sd &lt;- 0.2
x &lt;- 2 * runif(1000) + 1
f &lt;- function(x){x^3 - 6 * x^2 + 13 * x}
y &lt;- f(x) + rnorm(1000, sd = sd)
xy &lt;- data.frame(x=x, y=y)
x_test &lt;- seq(0.75, 3.25, length.out=101)
y_test &lt;- f(x_test) + rnorm(101, sd=sd)
xy_test &lt;- data.frame(x=x_test, y=y_test)

## Plot
nbin.max &lt;- 10
models &lt;- c(cv.aglm(x, y, use_LVar=FALSE, extrapolation="default", nbin.max=nbin.max),
            cv.aglm(x, y, use_LVar=FALSE, extrapolation="flat", nbin.max=nbin.max),
            cv.aglm(x, y, use_LVar=TRUE, extrapolation="default", nbin.max=nbin.max),
            cv.aglm(x, y, use_LVar=TRUE, extrapolation="flat", nbin.max=nbin.max))

titles &lt;- c("O-Dummies with extrapolation=\"default\"",
            "O-Dummies with extrapolation=\"flat\"",
            "L-Variables with extrapolation=\"default\"",
            "L-Variables with extrapolation=\"flat\"")

par.old &lt;- par(mfrow=c(2, 2))
for (i in 1:4) {
  model &lt;- models[[i]]
  title &lt;- titles[[i]]

  pred &lt;- predict(model, newx=x_test, s=model@lambda.min, type="response")

  plot(x_test, y_test, pch=20, col="grey", main=title)
  lines(x_test, f(x_test), lty="dashed", lwd=2)  # the theoretical line
  lines(x_test, pred, col="blue", lwd=3)  # the smoothed line by the model
}
par(par.old)
</code></pre>


</div>