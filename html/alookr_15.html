<div class="container">

<table style="width: 100%;"><tr>
<td>run_performance</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Apply calculate performance metrics for model evaluation</h2>

<h3>Description</h3>

<p>Apply calculate performance metrics for binary classification model evaluation.
</p>


<h3>Usage</h3>

<pre><code class="language-R">run_performance(model, actual = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>model</code></td>
<td>
<p>A model_df. results of predicted model that created by run_predict().</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>actual</code></td>
<td>
<p>factor. A data of target variable to evaluate the model. It supports factor that has binary class.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>run_performance() is performed in parallel when calculating the performance evaluation index. 
However, it is not supported in MS-Windows operating system and RStudio environment.
</p>


<h3>Value</h3>

<p>model_df. results of predicted model.
model_df is composed of tbl_df and contains the following variables.:
</p>

<ul>
<li>
<p> step : character. The current stage in the model fit process. The result of calling run_performance() is returned as "3.Performanced".
</p>
</li>
<li>
<p> model_id : character. Type of fit model.
</p>
</li>
<li>
<p> target : character. Name of target variable.
</p>
</li>
<li>
<p> positive : character. Level of positive class of binary classification.
</p>
</li>
<li>
<p> fitted_model : list. Fitted model object.
</p>
</li>
<li>
<p> predicted : list. Predicted value by individual model. Each value has a predict_class class object.
</p>
</li>
<li>
<p> performance : list. Calculate metrics by individual model. Each value has a numeric vector.
</p>
</li>
</ul>
<p>The performance metrics calculated are as follows.:
</p>

<ul>
<li>
<p> ZeroOneLoss : Normalized Zero-One Loss(Classification Error Loss).
</p>
</li>
<li>
<p> Accuracy : Accuracy.
</p>
</li>
<li>
<p> Precision : Precision.
</p>
</li>
<li>
<p> Recall : Recall.
</p>
</li>
<li>
<p> Sensitivity : Sensitivity.
</p>
</li>
<li>
<p> Specificity : Specificity.
</p>
</li>
<li>
<p> F1_Score : F1 Score.
</p>
</li>
<li>
<p> Fbeta_Score : F-Beta Score.
</p>
</li>
<li>
<p> LogLoss : Log loss / Cross-Entropy Loss.
</p>
</li>
<li>
<p> AUC : Area Under the Receiver Operating Characteristic Curve (ROC AUC).
</p>
</li>
<li>
<p> Gini : Gini Coefficient.
</p>
</li>
<li>
<p> PRAUC : Area Under the Precision-Recall Curve (PR AUC).
</p>
</li>
<li>
<p> LiftAUC : Area Under the Lift Chart.
</p>
</li>
<li>
<p> GainAUC : Area Under the Gain Chart.
</p>
</li>
<li>
<p> KS_Stat : Kolmogorov-Smirnov Statistic.
</p>
</li>
</ul>
<h3>Examples</h3>

<pre><code class="language-R">
library(dplyr)

# Divide the train data set and the test data set.
sb &lt;- rpart::kyphosis %&gt;%
  split_by(Kyphosis)

# Extract the train data set from original data set.
train &lt;- sb %&gt;%
  extract_set(set = "train")

# Extract the test data set from original data set.
test &lt;- sb %&gt;%
  extract_set(set = "test")

# Sampling for unbalanced data set using SMOTE(synthetic minority over-sampling technique).
train &lt;- sb %&gt;%
  sampling_target(seed = 1234L, method = "ubSMOTE")

# Cleaning the set.
train &lt;- train %&gt;%
  cleanse

# Run the model fitting.
result &lt;- run_models(.data = train, target = "Kyphosis", positive = "present")
result

# Predict the model. (Case 1)
pred &lt;- run_predict(result, test)
pred

# Calculate performace metrics. (Case 1)
perf &lt;- run_performance(pred)
perf
perf$performance

# Predict the model. (Case 2)
pred &lt;- run_predict(result, test[, -1])
pred

# Calculate performace metrics. (Case 2)
perf &lt;- run_performance(pred, pull(test[, 1]))
perf
perf$performance

# Convert to matrix for compare performace.
sapply(perf$performance, "c")


</code></pre>


</div>