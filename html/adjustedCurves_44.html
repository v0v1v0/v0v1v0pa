<div class="container">

<table style="width: 100%;"><tr>
<td>surv_prox_aiptw</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Proximal Augmented Inverse Probability of Treatment Weighted Survival Curve Estimates
</h2>

<h3>Description</h3>

<p>This page explains the details of estimating augmented inverse probability of treatment weighted survival curves using a proximal causal inference based method for single event time-to-event data (<code>method="prox_aiptw"</code> as described by Ying et al. (2022) in the <code>adjustedsurv</code> function). All regular arguments of the <code>adjustedsurv</code> function can be used. Additionally, the <code>treatment_proxy</code>, <code>outcome_proxy</code> and <code>adjust_vars</code> arguments have to be specified in the <code>adjustedsurv</code> call. Further arguments specific to this method are listed below.
</p>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>adjust_vars</code></td>
<td>

<p>[<strong>required</strong>] A character vector specifying names of variables in <code>data</code>. These variables may consist of observed confounders. At least one variable has to be named. Can be numeric, character or factor variables. Corresponds to <code class="reqn">X</code> (type 1 proxy) in the article by Ying et al. (2022).
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>treatment_proxy</code></td>
<td>

<p>[<strong>required</strong>] A single character string specifying the (numeric) variable that should be used as a treatment proxy. Corresponds to <code class="reqn">Z</code> (type 3 proxy) in the article by Ying et al. (2022).
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>outcome_proxy</code></td>
<td>

<p>[<strong>required</strong>] A single character string specifying the (numeric) variable that should be used as a outcome proxy. Corresponds to <code class="reqn">W</code> (type 2 proxy) in the article by Ying et al. (2022).
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>optim_method</code></td>
<td>

<p>A single character string passed to the <code>method</code> argument of the <code>optim</code> function, used internally when fitting the q-confounding bridge function and the h-confounding bridge function. Defaults to <code>"BFGS"</code>. To pass additional argument to the internal <code>optim</code> call, see argument <code>optim_control</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>optim_control</code></td>
<td>

<p>A list of named arguments passed to the <code>control</code> argument of the <code>optim</code> function, used internally when fitting the q-confounding bridge function and the h-confounding bridge function. Set to <code>list()</code> to not pass any additional argument (default).
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>return_fit</code></td>
<td>

<p>Whether to add intermediate results, such as the q-confounding bridge function to the output object. Defaults to <code>TRUE</code>.
</p>
</td>
</tr>
</table>
<h3>Details</h3>


<ul>
<li>
<p><strong>Type of Adjustment:</strong> Uses the proximal causal inference framework to adjust for measured and unmeasured confounding through the use of both the q-confounding bridge function and the h-confounding bridge function, which is essentially augmented inverse probability of treatment weighting, but using proxies.
</p>
</li>
<li>
<p><strong>Doubly-Robust:</strong> Estimates are Doubly-Robust in the sense that only one of the bridge functions has to be correctly specified to achieve unbiased estimates, given that the other relevant assumptions hold.
</p>
</li>
<li>
<p><strong>Categorical groups:</strong><code>variable</code> may only contain two groups. Must be a factor variable.
</p>
</li>
<li>
<p><strong>Approximate Variance:</strong> Calculations to approximate the variance and confidence intervals are available.
</p>
</li>
<li>
<p><strong>Allowed Time Values:</strong> Allows both continuous and integer time.
</p>
</li>
<li>
<p><strong>Bounded Estimates:</strong> Estimates are guaranteed to be bounded in the 0 to 1 probability range.
</p>
</li>
<li>
<p><strong>Monotone Function:</strong> Estimates are not guaranteed to be monotone.
</p>
</li>
<li>
<p><strong>Dependencies:</strong> Depends on <span class="pkg">numDeriv</span> and the dependencies of that package.
</p>
</li>
</ul>
<p>This method is based on the proximal causal inference framework, first introduced by Miao et al. (2018) and later extended to allow for estimation of counterfactual survival curves by Ying et al. (2022). It allows the estimation of the treatment-specific counterfactual survival curve under unmeasured confounding, when the true data-generation mechanism has a particular structure. In particular, there must be an observed variable (contained in the dataset) that is a potential cause of the treatment (<code>variable</code>) and also unrelated to the time-to-event endpoint, except through measured confounders (<code>adjust_vars</code>) and a particular known but unmeasured confounder. This type of variable is called a <code>treatment_proxy</code>. Secondly, there must be another observed variable that directly or indirectly causes the outcome, but is unrelated to the treatment expect through measured confounders and the same known but unmeasured confounder as mentioned earlier. This type of variable is called an <code>outcome_proxy</code>. A better explanation is given by Zivich et al. (2023). More information on the underlying assumptions can be found in the papers listed in the references.
</p>
<p>Ying et al. (2022) proposed two methods to utilize this kind of structure for the estimation of the counterfactual survival curve. The one implemented here relies on estimating the q-confounding bridge and the h-confounding bridge using parametric models. This essentially means that it uses both the treatment-assignment mechanism and the outcome-mechanism to adjust for confounding, similar to a regular augmented inverse probability weighted estimator.
</p>


<h3>Value</h3>

<p>Adds the following additional objects to the output of the <code>adjustedsurv</code> function:
</p>

<ul>
<li> <p><code>noncensor_cumhaz</code>: The estimated cumulative hazard function.
</p>
</li>
<li> <p><code>noncensor_cumhaz_IF</code>: The influence function based on the estimated cumulative hazard function.
</p>
</li>
<li> <p><code>q_bridge</code>: A <code>list</code> containing results from fitting the q-confounding bridge function.
</p>
</li>
<li> <p><code>h_bridge</code>: A <code>list</code> containing results from fitting the h-confounding bridge function.
</p>
</li>
</ul>
<h3>Author(s)</h3>

<p>Andrew Ying wrote all of the low-level estimation functions used to actually obtain the relevant values. Robin Denz wrote some wrapper functions around those to include this method in this package.
</p>


<h3>References</h3>

<p>Andrew Ying, Yifan Cui and Eric J. Tchetgen Tchetgen (2022). "Proximal Causal Inference for Marginal Counterfactual Survival Curves". arXiv:2204.13144
</p>
<p>Wang Miao, Zhi Geng and Eric J. Tchetgen Tchetgen (2018). "Identifying Causal Effects with Proxy Variables of an Unmeasured Confounder". In: Biometrika 105.4, pp. 987-993.
</p>
<p>Paul N. Zivich, Stephen R. Cole, Jessie K. Edwards, Grace E. Mulholland, Bonnie E. Shook-Sa and Eric J. Tchetgen Tchetgen (2023). "Introducing Proximal Causal Inference for Epidemiologists". In: American Journal of Epidemiology 192.7, pp. 1224-1227.
</p>
<p>Eric J. Tchetgen Tchetgen, Andrew Ying, Yifan Cui, Xu Shi and Wang Miao (2020). "An Introduction to Proximal Causal Learning". arXiv:2009.10982
</p>


<h3>See Also</h3>

<p><code>optim</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">library(adjustedCurves)

#### generate some example data that fufill all assumptions ####
# code was taken from the github repository associated with the original
# paper by Ying et al. (2022): https://github.com/andrewyyp/Proximal_MSF

# simulation parameters
para_set &lt;- list(mu_X = 1.1,
                 sigma_X = 0.75,
                 mu_U = 1.1,
                 sigma_U = 0.75,
                 alpha_A = c(0.3, 0.4, -0.6),
                 mu_Z = c(-0.2, -0.3, 0.65),
                 sigma_Z = 0.5,
                 mu_W = c(-0.6, 0.4, 0.65),
                 sigma_W = 0.5,
                 mu_T0 = c(0.1, 0.6, 0.25, 0.5),
                 mu_C = 0.2,
                 admin_C = 2
)

# small function to obtain the required data
data_gen &lt;- function(N, para_set, a = NULL) {
  # generate X, U
  X &lt;- para_set$mu_X + rnorm(N, 0, para_set$sigma_X)
  U &lt;- para_set$mu_U + rnorm(N, 0, para_set$sigma_U)
  X &lt;- pmax(X, 0)
  U &lt;- pmax(U, 0)

  if (is.null(a)) {
    # generate A
    prop_score_0 &lt;- 1/(1 + exp(-cbind(1, X, U) %*% para_set$alpha_A))
    A &lt;- rbinom(N, 1, prop_score_0)
  } else {
    A &lt;- rep(a, N)
  }


  # generate Z
  Z &lt;- cbind(1, X, U) %*% para_set$mu_Z + rnorm(N, 0, para_set$sigma_Z)

  # generate W
  W &lt;- cbind(1, X, U) %*% para_set$mu_W + rnorm(N, 0, para_set$sigma_W)


  #generate Y
  T0 &lt;- rexp(N, rate = cbind(1, A, X, U) %*% para_set$mu_T0)

  C &lt;- rexp(N, rate = para_set$mu_C)
  C &lt;- pmin(C, para_set$admin_C)
  if (is.null(a)) {
    df &lt;- data.frame(X, U, A, Z, W, T0 = pmin(T0, C), Delta = (T0 &lt;= C))
  } else {
    df &lt;- data.frame(X, U, A, Z, W, T0 = T0, Delta = rep(1, N))
  }
  return(df)
}

#### Simple example ####

set.seed(4356)
# NOTE: increase N to get more stable estimates, kept low here to pass
#       speed requirements set by CRAN
data &lt;- data_gen(N=50, para_set=para_set)
data$A &lt;- factor(data$A)

if (requireNamespace("numDeriv")) {

library(numDeriv)

adj &lt;- adjustedsurv(data=data,
                    variable="A",
                    ev_time="T0",
                    event="Delta",
                    method="prox_aiptw",
                    adjust_vars="X",
                    treatment_proxy="Z",
                    outcome_proxy="W",
                    conf_int=TRUE)
plot(adj, iso_reg=TRUE)
}
</code></pre>


</div>