<div class="container">

<table style="width: 100%;"><tr>
<td>et.abclass</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Tune Angle-Based Classifiers by ET-Lasso</h2>

<h3>Description</h3>

<p>Tune the regularization parameter for an angle-based large-margin classifier
by the ET-Lasso method (Yang, et al., 2019).
</p>


<h3>Usage</h3>

<pre><code class="language-R">et.abclass(
  x,
  y,
  intercept = TRUE,
  weight = NULL,
  loss = c("logistic", "boost", "hinge-boost", "lum"),
  control = list(),
  nstages = 2,
  refit = list(lambda = 1e-06),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>A numeric matrix representing the design matrix.  No missing valus
are allowed.  The coefficient estimates for constant columns will be
zero.  Thus, one should set the argument <code>intercept</code> to <code>TRUE</code>
to include an intercept term instead of adding an all-one column to
<code>x</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>An integer vector, a character vector, or a factor vector
representing the response label.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>intercept</code></td>
<td>
<p>A logical value indicating if an intercept should be
considered in the model.  The default value is <code>TRUE</code> and the
intercept is excluded from regularization.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>weight</code></td>
<td>
<p>A numeric vector for nonnegative observation weights. Equal
observation weights are used by default.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>loss</code></td>
<td>
<p>A character value specifying the loss function.  The available
options are <code>"logistic"</code> for the logistic deviance loss,
<code>"boost"</code> for the exponential loss approximating Boosting machines,
<code>"hinge-boost"</code> for hybrid of SVM and AdaBoost machine, and
<code>"lum"</code> for largin-margin unified machines (LUM).  See Liu, et
al. (2011) for details.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>control</code></td>
<td>
<p>A list of control parameters. See <code>abclass.control()</code>
for details.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nstages</code></td>
<td>
<p>A positive integer specifying for the number of stages in the
ET-Lasso procedure.  By default, two rounds of tuning by random
permutations will be performed as suggested in Yang, et al. (2019).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>refit</code></td>
<td>
<p>A logical value indicating if a new classifier should be
trained using the selected predictors.  This argument can also be a list
with named elements, which will be passed to <code>abclass.control()</code> to
specify how the new classifier should be trained.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Other control parameters passed to <code>abclass.control()</code>.</p>
</td>
</tr>
</table>
<h3>References</h3>

<p>Yang, S., Wen, J., Zhan, X., &amp; Kifer, D. (2019). ET-Lasso: A new efficient
tuning of lasso-type regularization for high-dimensional data. In
<em>Proceedings of the 25th ACM SIGKDD International Conference on
Knowledge Discovery &amp; Data Mining</em> (pp. 607â€“616).
</p>


</div>