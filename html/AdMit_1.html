<div class="container">

<table style="width: 100%;"><tr>
<td>AdMit</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Adaptive Mixture of Student-t Distributions</h2>

<h3>Description</h3>

<p>Function which performs the fitting of an adaptive mixture of
Student-t distributions to approximate a target density through its
kernel function</p>


<h3>Usage</h3>

<pre><code class="language-R">AdMit(KERNEL, mu0, Sigma0 = NULL, control = list(), ...)
</code></pre>


<h3>Arguments</h3>


<table>
<tr style="vertical-align: top;">
<td><code>KERNEL</code></td>
<td>
<p>kernel function of the target density on which the adaptive mixture is fitted. This
function should be vectorized for speed purposes (i.e., its first
argument should be a matrix and its output a vector). Moreover, the function must contain
the logical argument <code>log</code>. If <code>log = TRUE</code>, the function
returns (natural) logarithm values of the kernel function. <code>NA</code> and
<code>NaN</code> values are not allowed. (See *Details* for examples
of <code>KERNEL</code> implementation.)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mu0</code></td>
<td>
<p>initial value in the first stage optimization (for the location of
the first Student-t component) in the adaptive mixture, or
location of the first Student-t component if <code>Sigma0</code> is not <code>NULL</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Sigma0</code></td>
<td>
<p>scale matrix of the first Student-t component (square, symmetric and positive definite). Default:
<code>Sigma0 = NULL</code>, i.e., the scale matrix of the first Student-t
component is estimated by the function <code>AdMit</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>control</code></td>
<td>
<p>control parameters (see *Details*).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>further arguments to be passed to <code>KERNEL</code>.</p>
</td>
</tr>
</table>
<h3>Details</h3>


<p>The argument <code>KERNEL</code> is the kernel function of the target
density, and it should be vectorized for speed purposes.
</p>
<p>As a first example, consider the kernel function proposed by Gelman-Meng (1991):
</p>
<p style="text-align: center;"><code class="reqn">
    k(x_1,x_2) = \exp\left( -\frac{1}{2} [A x_1^2 x_2^2 + x_1^2 + x_2^2
    - 2 B x_1 x_2 - 2 C_1 x_1 - 2 C_2 x_2] \right)
  </code>
</p>

<p>where commonly used values
are <code class="reqn">A=1</code>, <code class="reqn">B=0</code>, <code class="reqn">C_1=3</code> and <code class="reqn">C_2=3</code>.
</p>
<p>A vectorized implementation of this function might be:
</p>
<pre>
    GelmanMeng &lt;- function(x, A = 1, B = 0, C1 = 3, C2 = 3, log = TRUE)
    {
      if (is.vector(x))
        x &lt;- matrix(x, nrow = 1)
      r &lt;- -.5 * (A * x[,1]^2 * x[,2]^2 + x[,1]^2 + x[,2]^2
                - 2 * B * x[,1] * x[,2] - 2 * C1 * x[,1] - 2 * C2 * x[,2])
      if (!log)
        r &lt;- exp(r)
      as.vector(r)
    }
  </pre>
<p>This way, we may supply a point <code class="reqn">(x_1,x_2)</code>
for <code>x</code> and the function will output a single value (i.e., the kernel
estimated at this point). But the function is vectorized, in the sense
that we may supply a <code class="reqn">(N \times 2)</code> matrix
of values for <code>x</code>, where rows of <code>x</code> are
points <code class="reqn">(x_1,x_2)</code> and the output will be a vector of
length <code class="reqn">N</code>, containing the kernel values for these points.
Since the <code>AdMit</code> procedure evaluates <code>KERNEL</code> for a
large number of points, a vectorized implementation is important. Note
also the additional argument <code>log = TRUE</code> which is used for
numerical stability.
</p>
<p>As a second example, consider the following (simple) econometric model:
</p>
<p style="text-align: center;"><code class="reqn">
    y_t \sim \, i.i.d. \, N(\mu,\sigma^2) \quad t=1,\ldots,T
  </code>
</p>

<p>where <code class="reqn">\mu</code> is the mean value and <code class="reqn">\sigma</code> is the
standard deviation. Our purpose is to estimate
<code class="reqn">\theta = (\mu,\sigma)</code> within a Bayesian
framework, based on a vector <code class="reqn">y</code> of <code class="reqn">T</code> observations; the
kernel thus consists of the product of the
prior and the likelihood function. As previously mentioned, the
kernel function should be vectorized, i.e., treat a <code class="reqn">(N \times 2)</code> matrix of points
<code class="reqn">\theta</code> for which the kernel will be evaluated.
Using the common (Jeffreys) prior <code class="reqn">p(\theta) = \frac{1}{\sigma}</code>
for <code class="reqn">\sigma &gt; 0</code>, a vectorized implementation of the
kernel function might be:
</p>
<pre>
     KERNEL &lt;- function(theta, y, log = TRUE)
     {
       if (is.vector(theta))
         theta &lt;- matrix(theta, nrow = 1)

       ## sub function which returns the log-kernel for a given
       ## thetai value (i.e., a given row of theta)
       KERNEL_sub &lt;- function(thetai)
       {
         if (thetai[2] &gt; 0) ## check if sigma&gt;0
	 { ## if yes, compute the log-kernel at thetai
           r &lt;- - log(thetai[2])
	         + sum(dnorm(y, thetai[1], thetai[2], TRUE))
	 }
	 else
	 { ## if no, returns -Infinity
	   r &lt;- -Inf
	 }
	 as.numeric(r)
       }

       ## 'apply' on the rows of theta (faster than a for loop)
       r &lt;- apply(theta, 1, KERNEL_sub)
       if (!log)
         r &lt;- exp(r)
       as.numeric(r)
     }
   </pre>
<p>Since this kernel function also depends on the vector <code class="reqn">y</code>, it
must be passed to <code>KERNEL</code> in the <code>AdMit</code> function. This is
achieved via the argument <code class="reqn">\ldots</code>, i.e., <code>AdMit(KERNEL, mu = c(0, 1), y = y)</code>.
</p>
<p>To gain even more speed, implementation of <code>KERNEL</code> might rely on C or Fortran
code using the functions <code>.C</code> and <code>.Fortran</code>. An example is
provided in the file ‘<span class="file">AdMitJSS.R</span>’ in the package's folder.
</p>
<p>The argument <code>control</code> is a list that can supply any of
the following components:
</p>

<dl>
<dt><code>Ns</code></dt>
<dd>
<p>number of draws used in the evaluation of the
importance sampling weights (integer number not smaller than 100). Default: <code>Ns = 1e5</code>.</p>
</dd>
<dt><code>Np</code></dt>
<dd>
<p>number of draws used in the optimization of the mixing
probabilities (integer number not smaller than 100 and not larger
than <code>Ns</code>). Default: <code>Np = 1e3</code>.</p>
</dd>
<dt><code>Hmax</code></dt>
<dd>
<p>maximum number of Student-t components in the
adaptive mixture (integer number not smaller than one). Default: <code>Hmax = 10</code>.</p>
</dd>
<dt><code>df</code></dt>
<dd>
<p>degrees of freedom parameter of the
Student-t components (real number not smaller than one). Default: <code>df = 1</code>.</p>
</dd>
<dt><code>CVtol</code></dt>
<dd>
<p>tolerance for the relative change of the coefficient of
variation (real number in [0,1]). The
adaptive algorithm stops if the new
component leads to a relative change in the coefficient of
variation that is smaller or equal than
<code>CVtol</code>. Default: <code>CVtol = 0.1</code>, i.e., 10%.</p>
</dd>
<dt><code>weightNC</code></dt>
<dd>
<p>weight assigned to the new
Student-t component of the adaptive mixture as
a starting value in the optimization of the mixing probabilities
(real number in [0,1]). Default: <code>weightNC = 0.1</code>, i.e., 10%.</p>
</dd>
<dt><code>trace</code></dt>
<dd>
<p>tracing information on
the adaptive fitting procedure (logical). Default:
<code>trace = FALSE</code>, i.e., no tracing information.</p>
</dd>
<dt><code>IS</code></dt>
<dd>
<p>should importance sampling be used to estimate the
mode and the scale matrix of the Student-t components (logical). Default: <code>IS = FALSE</code>,
i.e., use numerical optimization instead.</p>
</dd>
<dt><code>ISpercent</code></dt>
<dd>
<p>vector of percentage(s) of largest weights used to
estimate the mode and the scale matrix of the Student-t
components of the adaptive mixture by importance
sampling (real number(s) in [0,1]). Default:
<code>ISpercent = c(0.05, 0.15, 0.3)</code>, i.e., 5%, 15% and 30%.</p>
</dd>
<dt><code>ISscale</code></dt>
<dd>
<p>vector of scaling factor(s) used to rescale the
scale matrix of the mixture components (real positive numbers).
Default: <code>ISscale = c(1, 0.25, 4)</code>.</p>
</dd>
<dt><code>trace.mu</code></dt>
<dd>
<p>Tracing information on
the progress in the optimization of the mode of the mixture
components (non-negative integer number). Higher values
may produce more tracing information (see the source code
of the function <code>optim</code> for further details).
Default: <code>trace.mu = 0</code>, i.e., no tracing information.</p>
</dd>
<dt><code>maxit.mu</code></dt>
<dd>
<p>maximum number of iterations used
in the optimization of the modes of the mixture components
(positive integer). Default: <code>maxit.mu = 500</code>.</p>
</dd>
<dt><code>reltol.mu</code></dt>
<dd>
<p>relative convergence tolerance
used in the optimization of the modes of the mixture components
(real number in [0,1]). Default: <code>reltol.mu = 1e-8</code>.</p>
</dd>
<dt>
<code>trace.p</code>, <code>maxit.p</code>, <code>reltol.p</code>
</dt>
<dd>
<p>the same as for
the arguments above, but for the optimization of the mixing
probabilities of the mixture components.</p>
</dd>
</dl>
<h3>Value</h3>


<p>A list with the following components:<br></p>
<p><code>CV</code>: vector (of length <code class="reqn">H</code>) of coefficients of variation of
the importance sampling weights.<br></p>
<p><code>mit</code>: list (of length 4) containing information on the fitted mixture of
Student-t distributions, with the following components:<br></p>
<p><code>p</code>: vector (of length <code class="reqn">H</code>) of mixing probabilities.
<code>mu</code>: matrix (of size <code class="reqn">H \times d</code>) containing the
vectors of modes (in row) of the mixture components.
<code>Sigma</code>: matrix (of size <code class="reqn">H \times d^2</code>) containing the scale
matrices (in row) of the mixture components.
<code>df</code>: degrees of freedom parameter of the Student-t components.<br></p>
<p>where <code class="reqn">H (\geq 1)</code> is the number of components in the adaptive
mixture of Student-t distributions and <code class="reqn">d (\geq 1)</code> is
the dimension of the first argument in <code>KERNEL</code>.<br></p>
<p><code>summary</code>: data frame containing information on the optimization
procedures. It returns for each component of the adaptive mixture of
Student-t distribution: 1. the method used to estimate the mode
and the scale matrix of the Student-t component (‘USER’ if <code>Sigma0</code> is
provided by the user; numerical optimization: ‘BFGS’, ‘Nelder-Mead’;
importance sampling: ‘IS’, with percentage(s) of importance weights
used and scaling factor(s)); 2. the time required for this optimization;
3. the method used to estimate the mixing probabilities
(‘NLMINB’, ‘BFGS’, ‘Nelder-Mead’, ‘NONE’); 4. the time required for this
optimization; 5. the coefficient of variation of the importance
sampling weights.  
</p>


<h3>Note</h3>


<p>By using <code>AdMit</code> you agree to the following rules:
</p>

<ul>
<li>
<p> You must cite Ardia et al. (2009a,b) in working papers and published papers that use <code>AdMit</code>. Use <code>citation("AdMit")</code>.
</p>
</li>
<li>
<p> You must place the following URL in a footnote to help others find <code>AdMit</code>: <a href="https://CRAN.R-project.org/package=AdMit">https://CRAN.R-project.org/package=AdMit</a>. 
</p>
</li>
<li>
<p> You assume all risk for the use of <code>AdMit</code>.
</p>
</li>
</ul>
<p>Further details and examples of the <span style="font-family: Courier New, Courier; color: #666666;"><b>R</b></span> package <code>AdMit</code>
can be found in Ardia et al. (2009a,b). 
</p>
<p>Further details on the core algorithm are given in
Hoogerheide (2006), Hoogerheide, Kaashoek, van Dijk (2007) and
Hoogerheide, van Dijk (2008).
</p>
<p>The adaptive mixture <code>mit</code> returned by the function <code>AdMit</code> is used by the
function <code>AdMitIS</code> to perform importance sampling using
<code>mit</code> as the importance density or by the function <code>AdMitMH</code> to perform
independence chain Metropolis-Hastings sampling using <code>mit</code> as the
candidate density.
</p>


<h3>Author(s)</h3>


<p>David Ardia for the <span style="font-family: Courier New, Courier; color: #666666;"><b>R</b></span> port,
Lennart F. Hoogerheide and Herman K. van Dijk for the <code>AdMit</code> algorithm.
</p>


<h3>References</h3>


<p>Ardia, D., Hoogerheide, L.F., van Dijk, H.K. (2009a).
AdMit: Adaptive Mixture of Student-t Distributions.
<em>R Journal</em> <b>1</b>(1), pp.25-30.
doi: <a href="https://doi.org/10.32614/RJ-2009-003">10.32614/RJ-2009-003</a>
</p>
<p>Ardia, D., Hoogerheide, L.F., van Dijk, H.K. (2009b).
Adaptive Mixture of Student-t Distributions as a Flexible Candidate
Distribution for Efficient Simulation: The R Package AdMit.
<em>Journal of Statistical Software</em> <b>29</b>(3), pp.1-32.
doi: <a href="https://doi.org/10.18637/jss.v029.i03">10.18637/jss.v029.i03</a>
</p>
<p>Gelman, A., Meng, X.-L. (1991). 
A Note on Bivariate Distributions That Are Conditionally Normal. 
<em>The American Statistician</em> <b>45</b>(2), pp.125-126.
</p>
<p>Hoogerheide, L.F. (2006). 
<em>Essays on Neural Network Sampling Methods and Instrumental Variables</em>. 
PhD thesis, Tinbergen Institute, Erasmus University Rotterdam (NL). 
ISBN: 9051708261. 
(Book nr. 379 of the Tinbergen Institute Research Series.)
</p>
<p>Hoogerheide, L.F., Kaashoek, J.F., van Dijk, H.K. (2007). 
On the Shape of Posterior Densities and Credible Sets in Instrumental Variable Regression Models with Reduced
Rank: An Application of Flexible Sampling Methods using Neural Networks.
<em>Journal of Econometrics</em> <b>139</b>(1), pp.154-180. 
</p>
<p>Hoogerheide, L.F., van Dijk, H.K. (2008). 
Possibly Ill-Behaved Posteriors in Econometric Models: On the Connection between Model
Structures, Non-elliptical Credible Sets and Neural Network
Simulation Techniques. 
<em>Tinbergen Institute discussion paper</em> <b>2008-036/4</b>.
</p>


<h3>See Also</h3>


<p><code>AdMitIS</code> for importance sampling using an
adaptive mixture of Student-t distributions as the importance density,
<code>AdMitMH</code> for the independence chain Metropolis-Hastings
algorithm using an adaptive mixture of Student-t distributions as
the candidate density.
</p>


<h3>Examples</h3>

<pre><code class="language-R">
  ## NB : Low number of draws for speedup. Consider using more draws!
  ## Gelman and Meng (1991) kernel function
  GelmanMeng &lt;- function(x, A = 1, B = 0, C1 = 3, C2 = 3, log = TRUE)
  {
    if (is.vector(x))
      x &lt;- matrix(x, nrow = 1)
    r &lt;- -.5 * (A * x[,1]^2 * x[,2]^2 + x[,1]^2 + x[,2]^2
              - 2 * B * x[,1] * x[,2] - 2 * C1 * x[,1] - 2 * C2 * x[,2])
    if (!log)
      r &lt;- exp(r)
    as.vector(r)
  }

  ## Run AdMit (with default values)
  set.seed(1234)
  outAdMit &lt;- AdMit(GelmanMeng, mu0 = c(0.0, 0.1), control = list(Ns = 1e4))
  print(outAdMit)

  ## Run AdMit (using importance sampling to estimate
  ## the modes and the scale matrices)
  set.seed(1234)
  outAdMit &lt;- AdMit(KERNEL = GelmanMeng, 
                    mu0 = c(0.0, 0.1), 
                    control = list(IS = TRUE, Ns = 1e4))
  print(outAdMit)
</code></pre>


</div>