<div class="container">

<table style="width: 100%;"><tr>
<td>adaSample</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Implementation of AdaSampling for positive unlabelled and label noise
learning.</h2>

<h3>Description</h3>

<p><code>adaSample()</code> applies the AdaSampling procedure to reduce noise
in the training set, and subsequently trains a classifier from
the new training set. For each row (observation) in the test set, it
returns the probabilities of it being a positive ("P) or negative
("N") instance, as a two column data frame.
</p>


<h3>Usage</h3>

<pre><code class="language-R">adaSample(Ps, Ns, train.mat, test.mat, classifier = "svm", s = 1,
  C = 1, sampleFactor = 1, weights = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>Ps</code></td>
<td>
<p>names (each instance in the data has to be named) of positive examples</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Ns</code></td>
<td>
<p>names (each instance in the data has to be named) of negative examples</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>train.mat</code></td>
<td>
<p>training data matrix, without class labels.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>test.mat</code></td>
<td>
<p>test data matrix, without class labels.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>classifier</code></td>
<td>
<p>classification algorithm to be used for learning. Current options are
support vector machine, <code>"svm"</code>, k-nearest neighbour, <code>"knn"</code>, logistic regression <code>"logit"</code>,
linear discriminant analysis <code>"lda"</code>, and feature weighted knn, <code>"wKNN"</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>s</code></td>
<td>
<p>sets the seed.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>C</code></td>
<td>
<p>sets how many times to run the classifier, C&gt;1 induces an ensemble learning model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sampleFactor</code></td>
<td>
<p>provides a control on the sample size for resampling.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>weights</code></td>
<td>
<p>feature weights, required when using weighted knn.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p><code>adaSample()</code> is an adaptive sampling-based noise reduction method
to deal with noisy class labelled data, which acts as a wrapper for
traditional classifiers, such as support vector machines,
k-nearest neighbours, logistic regression, and linear discriminant
analysis.
</p>
<p>This process is used to build up a noise-minimized training set
that is derived by iteratively resampling the training set,
(<code>train</code>) based on probabilities derived after its classification.
</p>
<p>This sampled training set is then used to train a classifier, which
is then executed on the test set. <code>adaSample()</code> returns a series of
predictions for each row of the test set.
</p>
<p>Note that this function does not evaluate the quality of the model
and thus does not compare its output to true values of the test set.
To assess please see <code>adaSvmBenchmark()</code>.
</p>


<h3>Value</h3>

<p>a two column matrix providing classification probabilities of each sample 
with respect to positive and negative classes
</p>


<h3>References</h3>

<p>Yang, P., Liu, W., Yang. J. (2017) Positive unlabeled learning via wrapper-based
adaptive sampling. <em>International Joint Conferences on Artificial Intelligence (IJCAI)</em>, 3272-3279
</p>
<p>Yang, P., Ormerod, J., Liu, W., Ma, C., Zomaya, A., Yang, J.(2018) 
AdaSampling for positive-unlabeled and label noise learning with bioinformatics applications. 
<em>IEEE Transactions on Cybernetics</em>, doi:10.1109/TCYB.2018.2816984
</p>


<h3>Examples</h3>

<pre><code class="language-R"># Load the example dataset
data(brca)
head(brca)

# First, clean up the dataset to transform into the required format.
brca.mat &lt;- apply(X = brca[,-10], MARGIN = 2, FUN = as.numeric)
brca.cls &lt;- sapply(X = brca$cla, FUN = function(x) {ifelse(x == "malignant", 1, 0)})
rownames(brca.mat) &lt;- paste("p", 1:nrow(brca.mat), sep="_")

# Introduce 40% noise to positive class and 30% noise to the negative class
set.seed(1)
pos &lt;- which(brca.cls == 1)
neg &lt;- which(brca.cls == 0)
brca.cls.noisy &lt;- brca.cls
brca.cls.noisy[sample(pos, floor(length(pos) * 0.4))] &lt;- 0
brca.cls.noisy[sample(neg, floor(length(neg) * 0.3))] &lt;- 1

# Identify positive and negative examples from the noisy dataset
Ps &lt;- rownames(brca.mat)[which(brca.cls.noisy == 1)]
Ns &lt;- rownames(brca.mat)[which(brca.cls.noisy == 0)]

# Apply AdaSampling method on the noisy data
brca.preds &lt;- adaSample(Ps, Ns, train.mat=brca.mat, test.mat=brca.mat, classifier = "knn")
head(brca.preds)

# Orignal accuracy from the labels
accuracy &lt;- sum(brca.cls.noisy == brca.cls) / length(brca.cls)
accuracy

# Accuracy after applying AdaSampling method
accuracyWithAdaSample &lt;- sum(ifelse(brca.preds[,"P"] &gt; 0.5, 1, 0) == brca.cls) / length(brca.cls)
accuracyWithAdaSample

</code></pre>


</div>