<div class="container">

<table style="width: 100%;"><tr>
<td>SDAD</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Sparse Discriminant Analysis solved via ADMM</h2>

<h3>Description</h3>

<p>Applies alternating direction methods of multipliers algorithm to
the optimal scoring formulation of sparse discriminant analysis proposed
by Clemmensen et al. 2011.
</p>


<h3>Usage</h3>

<pre><code class="language-R">SDAD(Xt, ...)

## Default S3 method:
SDAD(
  Xt,
  Yt,
  Om,
  gam,
  lam,
  mu,
  q,
  PGsteps,
  PGtol,
  maxits,
  tol,
  selector = rep(1, dim(Xt)[2]),
  initTheta,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>Xt</code></td>
<td>
<p>n by p data matrix, (not a data frame, but a matrix)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Yt</code></td>
<td>
<p>n by K matrix of indicator variables (Yij = 1 if i in class j).
This will later be changed to handle factor variables as well.
Each observation belongs in a single class, so for a given row/observation,
only one element is 1 and the rest is 0.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Om</code></td>
<td>
<p>p by p parameter matrix Omega in generalized elastic net penalty.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>gam</code></td>
<td>
<p>Regularization parameter for elastic net penalty.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lam</code></td>
<td>
<p>Regularization parameter for l1 penalty, must be greater than zero.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mu</code></td>
<td>
<p>Penalty parameter for augmented Lagrangian term, must be greater than zero.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>q</code></td>
<td>
<p>Desired number of discriminant vectors.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>PGsteps</code></td>
<td>
<p>Maximum number if inner proximal gradient algorithm for finding beta.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>PGtol</code></td>
<td>
<p>Two stopping tolerances for inner ADMM method, first is absolute tolerance, second is relative.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>maxits</code></td>
<td>
<p>Number of iterations to run</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tol</code></td>
<td>
<p>Stopping tolerance for proximal gradient algorithm.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>selector</code></td>
<td>
<p>Vector to choose which parameters in the discriminant vector will be used to calculate the
regularization terms. The size of the vector must be *p* the number of predictors. The
default value is a vector of all ones. This is currently only used for ordinal classification.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>initTheta</code></td>
<td>
<p>Initial first theta, default value is a vector of ones.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p><code>SDAD</code> returns an object of <code>class</code> "<code>SDAD</code>" including a list
with the following named components: (More will be added later to handle the predict function)
</p>

<dl>
<dt><code>call</code></dt>
<dd>
<p>The matched call.</p>
</dd>
<dt><code>B</code></dt>
<dd>
<p>p by q matrix of discriminant vectors.</p>
</dd>
<dt><code>Q</code></dt>
<dd>
<p>K by q matrix of scoring vectors.</p>
</dd>
<dt><code>subits</code></dt>
<dd>
<p>Total number of iterations in proximal gradient subroutine.</p>
</dd>
<dt><code>totalits</code></dt>
<dd>
<p>Number coordinate descent iterations for all discriminant vectors</p>
</dd>
</dl>
<p><code>NULL</code>
</p>


<h3>See Also</h3>

<p><code>SDADcv</code>, <code>SDAAP</code> and <code>SDAP</code>
</p>


</div>