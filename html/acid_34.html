<div class="container">

<table style="width: 100%;"><tr>
<td>sadr.test</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2> Misspecification Test assessing a Parametric Conditional Income Distribution

</h2>

<h3>Description</h3>

<p> This function performs a misspecificaton test for a parametrically specified cdf estimated by (Bayesian) Structured Additive Distributional Regression. 

</p>


<h3>Usage</h3>

<pre><code class="language-R">sadr.test(data, y.pos = NULL, dist1, dist2, params.m, mcmc = TRUE, mcmc.params.a,
 ygrid, bsrep = 10, n.startvals = 300, dist.para.table)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p> a dataframe including dependent variable and all explanatory variables. 

</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y.pos</code></td>
<td>
<p> an integer indicating the position of the dependent variable in the dataframe. 

</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>dist1</code></td>
<td>
<p> character string with the name of the first continuous distribution used. Must be listed in dist.para.table. Must be equivalent to the respective function of that distribution, e.g. norm for the normal distribution.

</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>dist2</code></td>
<td>
<p>  character string with the name of the second continuous distribution used. Must be listed in dist.para.table. Must be equivalent to the respective function of that distribution, e.g. norm for the normal distribution.

</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>params.m</code></td>
<td>
<p> a matrix with the estimated parameter values (in colums) for each individual (in rows). The order of the parameters must be as follows: parameters for the first distribution, parameters for the second distribution, probability of zero income, probability of dist1, probability of dist2 and probability of dist1 given employment/non-zero income.

</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mcmc</code></td>
<td>
<p> logical; if TRUE, uncertainty as provided by the MCMC samples is considered.

</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mcmc.params.a</code></td>
<td>
<p> an array, with the mcmc samples for all the parameters specified by structured additive distributional regression. In the first dimension should be the MCMC realisations, in the second dimension the individuals and in the third the parameters. The order of the parameters must be as follows: parameters for the first distribution, parameters for the second distribution, probability of zero income, probability of dist1, probability of dist2 and probability of dist1 given employment/non-zero income.

</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ygrid</code></td>
<td>
<p> vector yielding the grid on which the cdf is specified.

</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>bsrep</code></td>
<td>
<p> integer giving the number of bootstrap repitions in order to determine the distributions of the test statistics under the null.

</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n.startvals</code></td>
<td>
<p> integer giving the maximum number of observations used to estimate the test statistic.

</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>dist.para.table</code></td>
<td>
<p> a table of the same form as <code>dist.para.t</code> with distribution name, function name and number of parameters.

</p>
</td>
</tr>
</table>
<h3>Value</h3>

<table>
<tr style="vertical-align: top;">
<td><code>teststat.ks</code></td>
<td>
<p> Kolmogorov-Smirnov test statistic.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pval.ks</code></td>
<td>
<p> p-value based on the Kolmogorov-Smirnov test statistic.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>teststat.cvm</code></td>
<td>
<p> Cramer-von-Mises test statistic.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pval.cvm</code></td>
<td>
<p> p-value based on the Cramer-von-Mises test statistic.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>test</code></td>
<td>
<p> type cdf considered for the test.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>param.distributions</code></td>
<td>
<p> parametric distributions assumed for dist1 and dist2.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>teststat.ks.bs</code></td>
<td>
<p> bootstrap results of Kolmogorov-Smirnov test statistic under null.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>teststat.cvm.bs</code></td>
<td>
<p> bootstrap results of Cramer-von-Mises test statistic under null.</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p> Alexander Sohn

</p>


<h3>References</h3>

<p>Rothe, C. and Wied, D. (2013): Misspecification Testing in a Class of Conditional Distributional Models, in: Journal of the American Statistical Association, Vol. 108(501), pp.314-324.
</p>
<p>Sohn, A. (forthcoming): Scars from the Past and Future Earning Distributions.
</p>


<h3>Examples</h3>

<pre><code class="language-R"># ### functions not run - take considerable time!
# 
# library(acid)
# data(dist.para.t)
# data(params)
# ### example one - two normals, no mcmc
# dist1&lt;-"norm"
# dist2&lt;-"norm"
# ## generating data
# set.seed(1234)
# n&lt;-1000
# sigma&lt;-0.1
# X.theta&lt;-c(1,10,1,10)
# X.gen&lt;-function(n,paras){
#   X&lt;-matrix(c(round(runif(n,paras[1],paras[2])),round(runif(n,paras[3],
#             paras[4]))),ncol=2)
#   return(X)
# }
# X &lt;- X.gen(n,X.theta)
# beta.mu1   &lt;- 1
# beta.sigma1&lt;- 0.1
# beta.mu2   &lt;- 2
# beta.sigma2&lt;- 0.1
# pi0        &lt;- 0.3
# pi01       &lt;- 0.8
# pi1        &lt;- (1-pi0)*pi01
# pi2        &lt;- 1-pi0-pi1
# 
# params.m&lt;-matrix(NA,n,8)
# params.m[,1]&lt;-(0+beta.mu1)*X[,1]
# params.m[,2]&lt;-(0+beta.sigma1)*X[,1]
# params.m[,3]&lt;-(0+beta.mu2)*X[,2]
# params.m[,4]&lt;-(0+beta.sigma2)*X[,2]
# params.m[,5]&lt;-pi0
# params.m[,6]&lt;-pi1
# params.m[,7]&lt;-pi2
# params.m[,8]&lt;-pi01
# 
# params.mF&lt;-matrix(NA,n,8)
# params.mF[,1]&lt;-(10+beta.mu1)*X[,1]
# params.mF[,2]&lt;-(0+beta.sigma1)*X[,1]
# params.mF[,3]&lt;-(0+beta.mu2)*X[,2]
# params.mF[,4]&lt;-(2+beta.sigma2)*X[,2]
# params.mF[,5]&lt;-pi0
# params.mF[,6]&lt;-pi1
# params.mF[,7]&lt;-pi2
# params.mF[,8]&lt;-pi01
# # starting repititions
# reps&lt;-30
# tsreps1T&lt;-rep(NA,reps)
# tsreps2T&lt;-rep(NA,reps)
# tsreps1F&lt;-rep(NA,reps)
# tsreps2F&lt;-rep(NA,reps)
# sys.t&lt;-Sys.time()
# for(r in 1:reps){
#   Y &lt;- rep(NA,n)
#   for(i in 1:n){
#     Y[i] &lt;- ysample.md(1,dist1,dist2,theta=params.m[i,1:4],params.m[i,5],
#     params.m[i,6],params.m[i,7],dist.para.t)
#   }
#   dat&lt;-cbind(Y,X)
#   y.pos&lt;-1
#   ygrid&lt;-seq(min(Y),round(max(Y)*1.2,-1),by=1)  
#   tsT&lt;-sadr.test(data=dat,y.pos=NULL,dist1="norm",dist2="norm",
#   params.m=params.m,mcmc=FALSE,mcmc.params=NA,ygrid=ygrid, bsrep=100,
#   n.startvals=30000,dist.para.table=dist.para.t)
#   tsreps1T[r]&lt;-tsT$pval.ks
#   tsreps2T[r]&lt;-tsT$pval.cvm
#   tsF&lt;-sadr.test(data=dat,y.pos=NULL,dist1="norm",dist2="norm",
#   params.m=params.mF,mcmc=FALSE,mcmc.params=NA,ygrid=ygrid, bsrep=100,
#   n.startvals=30000,dist.para.table=dist.para.t)
#   tsreps1F[r]&lt;-tsF$pval.ks
#   tsreps2F[r]&lt;-tsF$pval.cvm
# }
# time.taken&lt;-Sys.time()-sys.t
# time.taken
# cbind(tsreps1T,tsreps2T,tsreps1F,tsreps2F)
# 
# data(dist.para.t)
# data(params)
# 
# ### example two - Dagum and log-normal - no mcmc
# ##putting list elements from params into matrix form for params.m
# params.m&lt;-matrix(NA,length(params$aft.v),6+4)
# params.m[,1]&lt;-params[[which(names(params)=="bft.v")]]
# params.m[,2]&lt;-params[[which(names(params)=="aft.v")]]
# params.m[,3]&lt;-params[[which(names(params)=="cft.v")]]
# params.m[,4]&lt;-1
# params.m[,5]&lt;-params[[which(names(params)=="mupt.v")]]
# params.m[,6]&lt;-params[[which(names(params)=="sigmapt.v")]]
# params.m[,7]&lt;-params[[which(names(params)=="punemp.v")]]
# params.m[,8]&lt;-params[[which(names(params)=="pft.v")]]
# params.m[,9]&lt;-params[[which(names(params)=="ppt.v")]]
# params.m[,10]&lt;-params[[which(names(params)=="pemp.v")]]
# 
# set.seed(123)
# reps&lt;-30
# tsreps1T&lt;-rep(NA,reps)
# tsreps2T&lt;-rep(NA,reps)
# tsreps1F&lt;-rep(NA,reps)
# tsreps2F&lt;-rep(NA,reps)
# sys.t&lt;-Sys.time()
# for(r in 1:reps){ 
#   ## creates variables under consideration and dimnames
#   n  &lt;- dim(params.m)[1]
#   mcmcsize&lt;-params$mcmcsize
#   ages &lt;- params$ages
#   unems &lt;- params$unems
#   educlvls &lt;- params$educlvls
#   OW &lt;- params$OW
#   ## simulate two samples
#   ages.s &lt;- sample(ages,n,replace=TRUE)
#   unems.s&lt;- sample(unems,n,replace=TRUE)
#   edu.s  &lt;- sample(c(-1,1),n,replac=TRUE)
#   OW.s   &lt;- sample(c(-1,1),n,replac=TRUE)
#   y.sim&lt;-rep(NA,n)
#   p.sel&lt;-sample(1:dim(params.m)[1],n)
#   for(i in 1:n){
#     p&lt;-p.sel[i]
#     #p&lt;-sample(1:n,1) #select a random individual
#     y.sim[i]&lt;-ysample.md(1,"GB2","LOGNO",
#                          theta=c(params$bft.v[p],params$aft.v[p],
#                                  params$cft.v[p],1,
#                                  params$mupt.v[p],params$sigmapt.v[p]),
#                          params$punemp.v[p],params$pft.v[p],params$ppt.v[p],
#                          dist.para.t)
#   }
#   dat&lt;-cbind(y.sim,ages.s,unems.s,edu.s,OW.s)
#   y.simF&lt;- rnorm(n,mean(y.sim),sd(y.sim))
#   y.simF[y.simF&lt;0]&lt;-0
#   datF&lt;-dat
#   datF[,1]&lt;-y.simF
#   ygrid &lt;- seq(0,1e6,by=1000) #quantile(y,taus)
#   ##executing test
#   tsT&lt;-sadr.test(data=dat,y.pos=NULL,dist1="GB2",dist2="LOGNO",params.m=
#                  params.m[p.sel,],mcmc=FALSE,mcmc.params=NA,ygrid=ygrid, 
#                  bsrep=100,n.startvals=30000,dist.para.table=dist.para.t)
#   tsreps1T[r]&lt;-tsT$pval.ks
#   tsreps2T[r]&lt;-tsT$pval.cvm
#   tsF&lt;-sadr.test(data=datF,y.pos=NULL,dist1="GB2",dist2="LOGNO",
#                  params.m=params.m[p.sel,],mcmc=FALSE,mcmc.params=NA,
#                  ygrid=ygrid, 
#                  bsrep=100,n.startvals=30000,dist.para.table=dist.para.t)
#   tsreps1F[r]&lt;-tsF$pval.ks
#   tsreps2F[r]&lt;-tsF$pval.cvm
# }
# time.taken&lt;-Sys.time()-sys.t
# time.taken
# cbind(tsreps1T,tsreps2T,tsreps1F,tsreps2F)
# 
# 
# 
# 
# 
# ### example three - two normals, with mcmc
# set.seed(1234)
# n&lt;-1000 #no of observations
# m&lt;-100 #no of mcmc samples
# sigma&lt;-0.1
# X.theta&lt;-c(1,10,1,10)
# #without weights
# X.gen&lt;-function(n,paras){
#   X&lt;-matrix(c(round(runif(n,paras[1],paras[2])),round(runif(n,paras[3],
#             paras[4]))),ncol=2)
#   return(X)
# }
# X &lt;- X.gen(n,X.theta)
# 
# beta.mu1   &lt;- 1
# beta.sigma1&lt;- 0.1
# beta.mu2   &lt;- 2
# beta.sigma2&lt;- 0.1
# pi0        &lt;- 0.3
# pi01       &lt;- 0.8
# pi1        &lt;- (1-pi0)*pi01
# pi2        &lt;- 1-pi0-pi1
# 
# mcmc.params.a&lt;-array(NA,dim=c(m,n,8))
# mcmc.params.a[,,1]&lt;-(0+beta.mu1+rnorm(m,0,beta.mu1/10))%*%t(X[,1]) 
      #assume sd of mcmc as 10% of parameter value
# mcmc.params.a[,,2]&lt;-(0+beta.sigma1+rnorm(m,0,beta.sigma1/10))%*%t(X[,1]) 
      #must not be negative!, may be for other seed!
# mcmc.params.a[,,3]&lt;-(0+beta.mu2+rnorm(m,0,beta.mu2/10))%*%t(X[,2])
# mcmc.params.a[,,4]&lt;-(0+beta.sigma2+rnorm(m,0,beta.sigma2/10))%*%t(X[,2]) 
      #must not be negative!, may be for other seed!
# mcmc.params.a[,,5]&lt;-(pi0+rnorm(m,0,pi0/10))%*%t(rep(1,n))
# mcmc.params.a[,,8]&lt;-(pi01+rnorm(m,0,pi01/10))%*%t(rep(1,n))
# mcmc.params.a[,,6]&lt;-(1-mcmc.params.a[,,5])*mcmc.params.a[,,8]
# mcmc.params.a[,,7]&lt;-1-mcmc.params.a[,,5]-mcmc.params.a[,,6]
# 
# params.m&lt;-apply(mcmc.params.a,MARGIN=c(2,3),FUN=quantile,probs=0.5)
# 
# mcmc.params.aF&lt;-array(NA,dim=c(m,n,8))
# mcmc.params.aF[,,1]&lt;-(10+beta.mu1+rnorm(m,0,beta.mu1/10))%*%t(X[,1]) 
      #assume sd of mcmc as 10% of parameter value
# mcmc.params.aF[,,2]&lt;-(0+beta.sigma1+rnorm(m,0,beta.sigma1/10))%*%t(X[,1]) 
      #must not be negative!, may be for other seed!
# mcmc.params.aF[,,3]&lt;-(0+beta.mu2+rnorm(m,0,beta.mu2/10))%*%t(X[,2])
# mcmc.params.aF[,,4]&lt;-(2+beta.sigma2+rnorm(m,0,beta.sigma2/10))%*%t(X[,2]) 
      #must not be negative!, may be for other seed!
# mcmc.params.aF[,,5]&lt;-(pi0+rnorm(m,0,pi0/10))%*%t(rep(1,n))
# mcmc.params.aF[,,8]&lt;-(pi01+rnorm(m,0,pi01/10))%*%t(rep(1,n))
# mcmc.params.aF[,,6]&lt;-(1-mcmc.params.aF[,,5])*mcmc.params.aF[,,8]
# mcmc.params.aF[,,7]&lt;-1-mcmc.params.aF[,,5]-mcmc.params.aF[,,6]
# 
# params.mF&lt;-apply(mcmc.params.aF,MARGIN=c(2,3),FUN=quantile,probs=0.5)
# 
# reps&lt;-30
# tsreps1T&lt;-rep(NA,reps)
# tsreps2T&lt;-rep(NA,reps)
# tsreps1F&lt;-rep(NA,reps)
# tsreps2F&lt;-rep(NA,reps)
# sys.t&lt;-Sys.time()
# for(r in 1:reps){
#   Y &lt;- rep(NA,n)
#   for(i in 1:n){
#     Y[i] &lt;- ysample.md(1,dist1,dist2,theta=params.m[i,1:4],params.m[i,5],
#                        params.m[i,6],params.m[i,7],dist.para.t)
#   }  
#   dat&lt;-cbind(Y,X)
#   y.pos&lt;-1
#   ygrid&lt;-seq(min(Y),round(max(Y)*1.2,-1),by=1)  
#   tsT&lt;-sadr.test(data=dat,y.pos=NULL,dist1="norm",dist2="norm",params.m=
#                  params.m,mcmc=TRUE,mcmc.params=mcmc.params.a,ygrid=ygrid, 
#                  bsrep=100,n.startvals=30000,dist.para.table=dist.para.t)
#   tsreps1T[r]&lt;-tsT$pval.ks
#   tsreps2T[r]&lt;-tsT$pval.cvm
#   tsF&lt;-sadr.test(data=dat,y.pos=NULL,dist1="norm",dist2="norm",
#                  params.m=params.mF,mcmc=TRUE,mcmc.params=mcmc.params.aF,
#                  ygrid=ygrid, bsrep=100,n.startvals=30000,
#                  dist.para.table=dist.para.t)
#   tsreps1F[r]&lt;-tsF$pval.ks
#   tsreps2F[r]&lt;-tsF$pval.cvm
#   #c(ts$teststat.ks,ts$teststat.cvm)
#   #c(ts$pval.ks,ts$pval.cvm)
#   
# }
# time.taken&lt;-Sys.time()-sys.t
# time.taken
# cbind(tsreps1T,tsreps2T,tsreps1F,tsreps2F)
# 
# 
# 
# ### example four - two normals, with mcmc and slight deviation from truth 
#     in true params
# library(acid)
# data(dist.para.t)
# data(params)
# dist1&lt;-"norm"
# dist2&lt;-"norm"
# 
# set.seed(1234)
# n&lt;-1000 #no of observations
# m&lt;-100 #no of mcmc samples
# sigma&lt;-0.1
# X.theta&lt;-c(1,10,1,10)
# #without weights
# X.gen&lt;-function(n,paras){
#   X&lt;-matrix(c(round(runif(n,paras[1],paras[2])),round(runif(n,paras[3],
#             paras[4]))),ncol=2)
#   return(X)
# }
# X &lt;- X.gen(n,X.theta)
# 
# beta.mu1   &lt;- 1
# beta.sigma1&lt;- 0.1
# beta.mu2   &lt;- 2
# beta.sigma2&lt;- 0.1
# pi0        &lt;- 0.3
# pi01       &lt;- 0.8
# pi1        &lt;- (1-pi0)*pi01
# pi2        &lt;- 1-pi0-pi1
# 
# mcmc.params.a&lt;-array(NA,dim=c(m,n,8))
# mcmc.params.a[,,1]&lt;-(beta.mu1/10+beta.mu1+rnorm(m,0,beta.mu1/10))%*%t(X[,1]) 
       #assume sd of mcmc as 10% of parameter value
# mcmc.params.a[,,2]&lt;-(0+beta.sigma1+rnorm(m,0,beta.sigma1/10))%*%t(X[,1]) 
       #must not be negative!, may be for other seed!
# mcmc.params.a[,,3]&lt;-(0+beta.mu2+rnorm(m,0,beta.mu2/10))%*%t(X[,2])
# mcmc.params.a[,,4]&lt;-(beta.sigma2/10+beta.sigma2+rnorm(m,0,
#                      beta.sigma2/10))%*%t(X[,2]) 
       #must not be negative!, may be for other seed!
# mcmc.params.a[,,5]&lt;-(pi0+rnorm(m,0,pi0/10))%*%t(rep(1,n))
# mcmc.params.a[,,8]&lt;-(pi01+rnorm(m,0,pi01/10))%*%t(rep(1,n))
# mcmc.params.a[,,6]&lt;-(1-mcmc.params.a[,,5])*mcmc.params.a[,,8]
# mcmc.params.a[,,7]&lt;-1-mcmc.params.a[,,5]-mcmc.params.a[,,6]
# 
# params.m&lt;-apply(mcmc.params.a,MARGIN=c(2,3),FUN=quantile,probs=0.5)
# 
# mcmc.params.aF&lt;-array(NA,dim=c(m,n,8))
# mcmc.params.aF[,,1]&lt;-(10+beta.mu1+rnorm(m,0,beta.mu1/10))%*%t(X[,1]) 
       #assume sd of mcmc as 10% of parameter value
# mcmc.params.aF[,,2]&lt;-(0+beta.sigma1+rnorm(m,0,beta.sigma1/10))%*%t(X[,1]) 
       #must not be negative!, may be for other seed!
# mcmc.params.aF[,,3]&lt;-(0+beta.mu2+rnorm(m,0,beta.mu2/10))%*%t(X[,2])
# mcmc.params.aF[,,4]&lt;-(2+beta.sigma2+rnorm(m,0,beta.sigma2/10))%*%t(X[,2]) 
       #must not be negative!, may be for other seed!
# mcmc.params.aF[,,5]&lt;-(pi0+rnorm(m,0,pi0/10))%*%t(rep(1,n))
# mcmc.params.aF[,,8]&lt;-(pi01+rnorm(m,0,pi01/10))%*%t(rep(1,n))
# mcmc.params.aF[,,6]&lt;-(1-mcmc.params.aF[,,5])*mcmc.params.aF[,,8]
# mcmc.params.aF[,,7]&lt;-1-mcmc.params.aF[,,5]-mcmc.params.aF[,,6]
# 
# params.mF&lt;-apply(mcmc.params.aF,MARGIN=c(2,3),FUN=quantile,probs=0.5)
# 
# reps&lt;-30
# tsreps1T&lt;-rep(NA,reps)
# tsreps2T&lt;-rep(NA,reps)
# tsreps1F&lt;-rep(NA,reps)
# tsreps2F&lt;-rep(NA,reps)
# sys.t&lt;-Sys.time()
# for(r in 1:reps){
#   Y &lt;- rep(NA,n)
#   for(i in 1:n){
#     Y[i] &lt;- ysample.md(1,dist1,dist2,theta=params.m[i,1:4],params.m[i,5],
#                        params.m[i,6],params.m[i,7],dist.para.t)
#   }
#   
#   dat&lt;-cbind(Y,X)
#   y.pos&lt;-1
#   ygrid&lt;-seq(min(Y),round(max(Y)*1.2,-1),by=1)  
#   tsT&lt;-sadr.test(data=dat,y.pos=NULL,dist1="norm",dist2="norm",
#                  params.m=params.m,mcmc=TRUE,mcmc.params=mcmc.params.a,
#                  ygrid=ygrid, bsrep=100,n.startvals=30000,
#                  dist.para.table=dist.para.t)
#   tsreps1T[r]&lt;-tsT$pval.ks
#   tsreps2T[r]&lt;-tsT$pval.cvm
#   tsF&lt;-sadr.test(data=dat,y.pos=NULL,dist1="norm",dist2="norm",
#                  params.m=params.mF,mcmc=TRUE,mcmc.params=mcmc.params.aF,
#                  ygrid=ygrid, bsrep=100,n.startvals=30000,
#                  dist.para.table=dist.para.t)
#   tsreps1F[r]&lt;-tsF$pval.ks
#   tsreps2F[r]&lt;-tsF$pval.cvm
#   #c(ts$teststat.ks,ts$teststat.cvm)
#   #c(ts$pval.ks,ts$pval.cvm)
#   
# }
# time.taken&lt;-Sys.time()-sys.t
# time.taken
# cbind(tsreps1T,tsreps2T,tsreps1F,tsreps2F)



</code></pre>


</div>