<div class="container">

<table style="width: 100%;"><tr>
<td>print.aggTrees.inference</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Print Method for aggTrees.inference Objects</h2>

<h3>Description</h3>

<p>Prints an <code>aggTrees.inference</code> object.
</p>


<h3>Usage</h3>

<pre><code class="language-R">## S3 method for class 'aggTrees.inference'
print(x, table = "avg_char", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p><code>aggTrees.inference</code> object.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>table</code></td>
<td>
<p>Either <code>"avg_char"</code> or <code>"diff"</code>, controls which table must be produced.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>A description of each table is provided in its caption.<br></p>
<p>Some covariates may feature zero variation in some leaf. This generally happens to dummy variables used to split some
nodes. In this case, when <code>table == "avg_char"</code> a warning message is produced displaying the names of the covariates
with zero variation in one or more leaves. The user should correct the table by removing the associated standard errors.<br></p>
<p>Compilation of the LATEX code requires the following packages: <code>booktabs</code>, <code>float</code>, <code>adjustbox</code>,
<code>multirow</code>.
</p>


<h3>Value</h3>

<p>Prints LATEX code.
</p>


<h3>Author(s)</h3>

<p>Riccardo Di Francesco
</p>


<h3>References</h3>


<ul><li>
<p> Di Francesco, R. (2022). Aggregation Trees. CEIS Research Paper, 546. <a href="https://doi.org/10.2139/ssrn.4304256">doi:10.2139/ssrn.4304256</a>.
</p>
</li></ul>
<h3>See Also</h3>

<p><code>build_aggtree</code>, <code>inference_aggtree</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">## Generate data.
set.seed(1986)

n &lt;- 1000
k &lt;- 3

X &lt;- matrix(rnorm(n * k), ncol = k)
colnames(X) &lt;- paste0("x", seq_len(k))
D &lt;- rbinom(n, size = 1, prob = 0.5)
mu0 &lt;- 0.5 * X[, 1]
mu1 &lt;- 0.5 * X[, 1] + X[, 2]
Y &lt;- mu0 + D * (mu1 - mu0) + rnorm(n)

## Training-honest sample split.
honest_frac &lt;- 0.5
splits &lt;- sample_split(length(Y), training_frac = (1 - honest_frac))
training_idx &lt;- splits$training_idx
honest_idx &lt;- splits$honest_idx

Y_tr &lt;- Y[training_idx]
D_tr &lt;- D[training_idx]
X_tr &lt;- X[training_idx, ]

Y_hon &lt;- Y[honest_idx]
D_hon &lt;- D[honest_idx]
X_hon &lt;- X[honest_idx, ]

## Construct sequence of groupings. CATEs estimated internally.
groupings &lt;- build_aggtree(Y_tr, D_tr, X_tr,
                           Y_hon, D_hon, X_hon)

## Analyze results with 4 groups.
results &lt;- inference_aggtree(groupings, n_groups = 4)

## Print results.
print(results, table = "diff")
print(results, table = "avg_char")

</code></pre>


</div>