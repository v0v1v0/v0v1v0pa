<div class="container">

<table style="width: 100%;"><tr>
<td>anomaly-package</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Detecting Anomalies in Data
</h2>

<h3>Description</h3>

<p>The <span class="pkg">anomaly</span> package provides methods for detecting collective and point anomalies in both univariate and multivariate settings.
</p>


<h3>Introduction</h3>

<p>The <span class="pkg">anomaly</span> package implements a number of recently proposed methods for anomaly detection. For univariate data there is the Collective And Point Anomaly (CAPA)
method of Fisch, Eckley and Fearnhead (2022a), which can detect both collective and point anomalies. For multivariate data there are three methods, the multivariate extension of CAPA
of Fisch, Eckley and Fearnhead (2022b), the Proportion Adaptive Segment
Selection (PASS) method of Jeng, Cai and Li, and a Bayesian approach, Bayesian Abnormal
Region Detector, of Bardwell and Fearnhead.
</p>
<p>The multivariate CAPA method and PASS are similar in that, for a given segment they use a likelihood-based approach to measure the evidence that it is anomalous for each component of the
multivariate data stream, and then merge this evidence across
components. They differ in how they merge this evidence, with PASS using
higher criticism (Donoho and Jin) and CAPA using
a penalised
likelihood approach. One disadvantage of the higher criticism approach for merging evidence is that it can lose power when only one or a very small number of components are anomalous. Furthermore,
CAPA also allows for point anomalies in otherwise normal segments of data, and can be more robust to detecting collective anomalies when there are point anomalies in the data. CAPA can also allow for
the anomalies segments to be slightly mis-aligned across different components. 
</p>
<p>The BARD method considers a similar model to that of CAPA or PASS, but is Bayesian and so its basic output are samples from the posterior distribution for where the collective anomalies are, and which
components are anomalous. It does not allow for point anomalies. As with any Bayesian method, it requires the user to specify suitable priors, but the output is more flexible, and can more directly
allow for quantifying uncertainty about the anomalies.
</p>


<h3>References</h3>

<p>Fisch ATM, Grose D, Eckley IA, Fearnhead P, Bardwell L (2024).
“anomaly: Detection of Anomalous Structure in Time Series Data.”
<em>Journal of Statistical Software</em>, <b>110</b>(1), 1–24.
<a href="https://doi.org/10.18637/jss.v110.i01">doi:10.18637/jss.v110.i01</a>.
</p>
<p>Fisch ATM, Eckley IA, Fearnhead P (2022a).
“A linear time method for the detection of collective and point anomalies.”
<em>Statistical Analysis and Data Mining: The ASA Data Science Journal</em>, <b>15</b>(4), 494-508.
<a href="https://doi.org/10.1002/sam.11586">doi:10.1002/sam.11586</a>.
</p>
<p>Fisch ATM, Eckley IA, Fearnhead P (2022b).
“Subset Multivariate Collective and Point Anomaly Detection.”
<em>Journal of Computational and Graphical Statistics</em>, <b>31</b>(2), 574-585.
<a href="https://doi.org/10.1080/10618600.2021.1987257">doi:10.1080/10618600.2021.1987257</a>.
</p>
<p>Jeng XJ, Cai TT, Li H (2012).
“Simultaneous discovery of rare and common segment variants.”
<em>Biometrika</em>, <b>100</b>(1), 157-172.
ISSN 0006-3444, <a href="https://doi.org/10.1093/biomet/ass059">doi:10.1093/biomet/ass059</a>, <a href="https://academic.oup.com/biomet/article/100/1/157/193108">https://academic.oup.com/biomet/article/100/1/157/193108</a>.
</p>
<p>Bardwell L, Fearnhead P (2017).
“Bayesian Detection of Abnormal Segments in Multiple Time Series.”
<em>Bayesian Anal.</em>, <b>12</b>(1), 193–218.
</p>
<p>Donoho D, Jin J (2004).
“Higher Criticism for Detecting Sparse Heterogeneous Mixtures.”
<em>The Annals of Statistics</em>, <b>32</b>(3), 962–994.
<a href="https://doi.org/10.1214/009053604000000265">doi:10.1214/009053604000000265</a>.
</p>


<h3>Examples</h3>

<pre><code class="language-R"># Use univariate CAPA to analyse simulated data
library("anomaly")
set.seed(0)
x &lt;- rnorm(5000)
x[401:500] &lt;- rnorm(100, 4, 1)
x[1601:1800] &lt;- rnorm(200, 0, 0.01)
x[3201:3500] &lt;- rnorm(300, 0, 10)
x[c(1000, 2000, 3000, 4000)] &lt;- rnorm(4, 0, 100)
x &lt;- (x - median(x)) / mad(x)
res &lt;- capa(x)
# view results
summary(res)
# visualise results
plot(res)

# Use multivariate CAPA to analyse simulated data
library("anomaly")
data("simulated")
# set penalties
beta &lt;- 2 * log(ncol(sim.data):1)
beta[1] &lt;- beta[1] + 3 * log(nrow(sim.data))
res &lt;- capa(sim.data, type= "mean", min_seg_len = 2,beta = beta)
# view results
summary(res)
# visualise results
plot(res, subset = 1:20)

# Use PASS to analyse simulated mutivariate data
library("anomaly")
data("simulated")
res &lt;- pass(sim.data, max_seg_len = 20, alpha = 3)
# view results
collective_anomalies(res)
# visualise results
plot(res)

# Use BARD to analyse simulated mutivariate data
library("anomaly")
data("simulated")
bard.res &lt;- bard(sim.data)
# sample from the BARD result
sampler.res &lt;- sampler(bard.res, gamma = 1/3, num_draws = 1000)
# view results
show(sampler.res)
# visualise results
plot(sampler.res, marginals = TRUE)

</code></pre>


</div>