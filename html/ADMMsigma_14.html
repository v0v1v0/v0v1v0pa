<div class="container">

<table style="width: 100%;"><tr>
<td>RIDGEsigma</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Ridge penalized precision matrix estimation</h2>

<h3>Description</h3>

<p>Ridge penalized matrix estimation via closed-form solution. If one is only interested in the ridge penalty, this function will be faster and provide a more precise estimate than using <code>ADMMsigma</code>. <br>
Consider the case where
<code class="reqn">X_{1}, ..., X_{n}</code> are iid <code class="reqn">N_{p}(\mu, \Sigma)</code>
and we are tasked with estimating the precision matrix,
denoted <code class="reqn">\Omega \equiv \Sigma^{-1}</code>. This function solves the
following optimization problem:
</p>

<dl>
<dt>Objective:</dt>
<dd>
<p><code class="reqn">\hat{\Omega}_{\lambda} = \arg\min_{\Omega \in S_{+}^{p}}
\left\{ Tr\left(S\Omega\right) - \log \det\left(\Omega \right) +
\frac{\lambda}{2}\left\| \Omega \right\|_{F}^{2} \right\}</code></p>
</dd>
</dl>
<p>where <code class="reqn">\lambda &gt; 0</code> and <code class="reqn">\left\|\cdot \right\|_{F}^{2}</code> is the Frobenius
norm.
</p>


<h3>Usage</h3>

<pre><code class="language-R">RIDGEsigma(X = NULL, S = NULL, lam = 10^seq(-2, 2, 0.1), path = FALSE,
  K = 5, cores = 1, trace = c("none", "progress", "print"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>
<p>option to provide a nxp data matrix. Each row corresponds to a single observation and each column contains n observations of a single feature/variable.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>S</code></td>
<td>
<p>option to provide a pxp sample covariance matrix (denominator n). If argument is <code>NULL</code> and <code>X</code> is provided instead then <code>S</code> will be computed automatically.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lam</code></td>
<td>
<p>positive tuning parameters for ridge penalty. If a vector of parameters is provided, they should be in increasing order. Defaults to grid of values <code>10^seq(-2, 2, 0.1)</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>path</code></td>
<td>
<p>option to return the regularization path. This option should be used with extreme care if the dimension is large. If set to TRUE, cores will be set to 1 and errors and optimal tuning parameters will based on the full sample. Defaults to FALSE.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>K</code></td>
<td>
<p>specify the number of folds for cross validation.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cores</code></td>
<td>
<p>option to run CV in parallel. Defaults to <code>cores = 1</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>trace</code></td>
<td>
<p>option to display progress of CV. Choose one of <code>progress</code> to print a progress bar, <code>print</code> to print completed tuning parameters, or <code>none</code>.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>returns class object <code>RIDGEsigma</code> which includes:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>Lambda</code></td>
<td>
<p>optimal tuning parameter.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Lambdas</code></td>
<td>
<p>grid of lambda values for CV.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Omega</code></td>
<td>
<p>estimated penalized precision matrix.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Sigma</code></td>
<td>
<p>estimated covariance matrix from the penalized precision matrix (inverse of Omega).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Path</code></td>
<td>
<p>array containing the solution path. Solutions are ordered dense to sparse.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Gradient</code></td>
<td>
<p>gradient of optimization function (penalized gaussian likelihood).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>MIN.error</code></td>
<td>
<p>minimum average cross validation error (cv.crit) for optimal parameters.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>AVG.error</code></td>
<td>
<p>average cross validation error (cv.crit) across all folds.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>CV.error</code></td>
<td>
<p>cross validation errors (cv.crit).</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Matt Galloway <a href="mailto:gall0441@umn.edu">gall0441@umn.edu</a>
</p>


<h3>References</h3>


<ul><li>
<p> Rothman, Adam. 2017. 'STAT 8931 notes on an algorithm to compute the Lasso-penalized Gaussian likelihood precision matrix estimator.'
</p>
</li></ul>
<h3>See Also</h3>

<p><code>plot.RIDGE</code>, <code>ADMMsigma</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R"># generate data from a sparse matrix
# first compute covariance matrix
S = matrix(0.7, nrow = 5, ncol = 5)
for (i in 1:5){
 for (j in 1:5){
   S[i, j] = S[i, j]^abs(i - j)
 }
 }

# generate 100 x 5 matrix with rows drawn from iid N_p(0, S)
set.seed(123)
Z = matrix(rnorm(100*5), nrow = 100, ncol = 5)
out = eigen(S, symmetric = TRUE)
S.sqrt = out$vectors %*% diag(out$values^0.5)
S.sqrt = S.sqrt %*% t(out$vectors)
X = Z %*% S.sqrt

# ridge penalty no ADMM
RIDGEsigma(X, lam = 10^seq(-5, 5, 0.5))
</code></pre>


</div>