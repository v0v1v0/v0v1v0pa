<div class="container">

<table style="width: 100%;"><tr>
<td>c_hat</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Estimate Dispersion for Poisson and Binomial GLM's and GLMM's
</h2>

<h3>Description</h3>

<p>Functions to compute an estimate of c-hat for binomial or Poisson GLM's
and GLMM's using different estimators of overdispersion.
</p>


<h3>Usage</h3>

<pre><code class="language-R">c_hat(mod, method = "pearson", ...)

## S3 method for class 'glm'
c_hat(mod, method = "pearson", ...)

## S3 method for class 'glmmTMB'
c_hat(mod, method = "pearson", ...)

## S3 method for class 'merMod'
c_hat(mod, method = "pearson", ...)

## S3 method for class 'vglm'
c_hat(mod, method = "pearson", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>mod</code></td>
<td>

<p>an object of class <code>glm</code>, <code>glmmTMB</code>, <code>merMod</code>, or
<code>vglm</code> for which a c-hat estimate is required.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>

<p>this argument defines the estimator used.  The default
<code>"pearson"</code> uses the Pearson chi-square divided by the residual
degrees of freedom.  Other methods include <code>"deviance"</code> consisting
of the residual deviance divided by the residual degrees of freedom,
<code>"farrington"</code> for the estimator suggested by Farrington (1996),
and <code>"fletcher"</code> for the estimator suggested by Fletcher (2012).
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>

<p>additional arguments passed to the function.
</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Poisson and binomial GLM's do not have a parameter for the variance and
it is usually held fixed to 1 (i.e., mean = variance).  However, one must
check whether this assumption is appropriate by estimating the
overdispersion parameter (c-hat).  Though one can obtain an estimate of
c-hat by dividing the residual deviance by the residual degrees of
freedom (i.e., <code>method = "deviance"</code>), McCullagh and Nelder (1989) and
Venables and Ripley (2002) recommend using Pearson's chi-square divided
by the residual degrees of freedom (<code>method = "pearson"</code>).  An
estimator based on Farrington (1996) is also implemented by the function
using the argument <code>method = "farrington"</code>.  Recent work by
Fletcher (2012) suggests that an alternative estimator performs better
than the above-mentioned methods in the presence of sparse data and is
now implemented with <code>method = "fletcher"</code>.  For GLMM's, only the
Pearson chi-square estimator of overdispersion is currently implemented. 
</p>
<p>Note that values of c-hat &gt; 1 indicate overdispersion (variance &gt; mean),
but that values much higher than 1 (i.e., &gt; 4) probably indicate
lack-of-fit.  In cases of moderate overdispersion, one usually
multiplies the variance-covariance matrix of the estimates by c-hat.  As
a result, the SE's of the estimates are inflated (c-hat is also known as
a variance inflation factor). 
</p>
<p>In model selection, c-hat should be estimated from the global model of
the candidate model set and the same value of c-hat applied to the
entire model set.  Specifically, a global model is the most complex model
which can be simplified to obtain all the other (nested) models of the
set.  When no single global model exists in the set of models
considered, such as when sample size does not allow a complex model, one
can estimate c-hat from 'subglobal' models.  Here, 'subglobal' models 
denote models from which only a subset of the models of the candidate
set can be derived.  In such cases, one can use the smallest value of
c-hat for model selection (Burnham and Anderson 2002).
</p>
<p>Note that c-hat counts as an additional parameter estimated and should
be added to <em>K</em>.  All functions in package <code>AICcmodavg</code>
automatically add 1 when the <code>c.hat</code> argument &gt; 1 and apply the
same value of c-hat for the entire model set.  When <code>c.hat &gt; 1</code>,
functions compute quasi-likelihood information criteria (either QAICc or
QAIC, depending on the value of the <code>second.ord</code> argument) by
scaling the log-likelihood of the model by <code>c.hat</code>.  The value of
<code>c.hat</code> can influence the ranking of the models:  as c-hat
increases, QAIC or QAICc will favor models with fewer parameters.  As an
additional check against this potential problem, one can create several
model selection tables by incrementing values of c-hat to assess the
model selection uncertainty.  If ranking changes little up to the c-hat
value observed, one can be confident in making inference. 
</p>
<p>In cases of underdispersion (c-hat &lt; 1), it is recommended to keep the
value of <code>c.hat</code> to 1.  However, note that values of c-hat &lt;&lt; 1 can
also indicate lack-of-fit and that an alternative model (and distribution)
should be investigated. 
</p>
<p>Note that <code>c_hat</code> only supports the estimation of c-hat for
binomial models with trials &gt; 1 (i.e., success/trial or cbind(success,
failure) syntax) or with Poisson GLM's or GLMM's.
</p>


<h3>Value</h3>

<p><code>c_hat</code> returns an object of class <code>c_hat</code> with the estimated
c-hat value and an attribute for the type of estimator used.
</p>


<h3>Author(s)</h3>

<p>Marc J. Mazerolle
</p>


<h3>References</h3>

<p>Anderson, D. R. (2008) <em>Model-based Inference in the Life Sciences:
a primer on evidence</em>. Springer: New York. 
</p>
<p>Burnham, K. P., Anderson, D. R. (2002) <em>Model Selection and
Multimodel Inference: a practical information-theoretic
approach</em>. Second edition. Springer: New York.
</p>
<p>Burnham, K. P., Anderson, D. R. (2004) Multimodel inference:
understanding AIC and BIC in model selection. <em>Sociological
Methods and Research</em> <b>33</b>, 261–304. 
</p>
<p>Farrington, C. P. (1996) On assessing goodness of fit of generalized
linear models to sparse data. <em>Journal of the Royal Statistical
Society B</em> <b>58</b>, 349–360.
</p>
<p>Fletcher, D. J. (2012) Estimating overdispersion when fitting a
generalized linear model to sparse data. <em>Biometrika</em> <b>99</b>,
230–237.
</p>
<p>Mazerolle, M. J. (2006) Improving data analysis in herpetology: using
Akaike's Information Criterion (AIC) to assess the strength of
biological hypotheses. <em>Amphibia-Reptilia</em> <b>27</b>, 169–180. 
</p>
<p>McCullagh, P., Nelder, J. A. (1989) <em>Generalized Linear
Models</em>. Second edition. Chapman and Hall: New York.
</p>
<p>Venables, W. N., Ripley, B. D. (2002) <em>Modern Applied Statistics
with S</em>. Second edition. Springer: New York. 
</p>


<h3>See Also</h3>

<p><code>AICc</code>, <code>confset</code>, <code>evidence</code>, 
<code>modavg</code>, <code>importance</code>,
<code>modavgPred</code>, <code>mb.gof.test</code>,
<code>Nmix.gof.test</code>, <code>anovaOD</code>, <code>summaryOD</code> 
</p>


<h3>Examples</h3>

<pre><code class="language-R">#binomial glm example
set.seed(seed = 10)
resp &lt;- rbinom(n = 60, size = 1, prob = 0.5)
set.seed(seed = 10)
treat &lt;- as.factor(sample(c(rep(x = "m", times = 30), rep(x = "f",
                                           times = 30))))
age &lt;- as.factor(c(rep("young", 20), rep("med", 20), rep("old", 20)))
#each invidual has its own response (n = 1)
mod1 &lt;- glm(resp ~ treat + age, family = binomial)
## Not run: 
c_hat(mod1) #gives an error because model not appropriate for
##computation of c-hat

## End(Not run)

##computing table to summarize successes
table(resp, treat, age)
dat2 &lt;- as.data.frame(table(resp, treat, age)) #not quite what we need
data2 &lt;- data.frame(success = c(9, 4, 2, 3, 5, 2),
                    sex = c("f", "m", "f", "m", "f", "m"),
                    age = c("med", "med", "old", "old", "young",
                      "young"), total = c(13, 7, 10, 10, 7, 13))
data2$prop &lt;- data2$success/data2$total
data2$fail &lt;- data2$total - data2$success

##run model with success/total syntax using weights argument
mod2 &lt;- glm(prop ~ sex + age, family = binomial, weights = total,
            data = data2)
c_hat(mod2)

##run model with other syntax cbind(success, fail)
mod3 &lt;- glm(cbind(success, fail) ~ sex + age, family = binomial,
            data = data2) 
c_hat(mod3)
</code></pre>


</div>