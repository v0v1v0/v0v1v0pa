<div class="container">

<table style="width: 100%;"><tr>
<td>Ake-package</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Associated kernel estimations
</h2>

<h3>Description</h3>

<p>Continuous and discrete estimation of density <code>dke.fun</code>, probability mass function (p.m.f.) <code>kpmfe.fun</code> and regression <code>reg.fun</code> functions are performed using  continuous and discrete associated kernels. The cross-validation technique <code>hcvc.fun</code>, <code>hcvreg.fun</code> and the Bayesian procedure <code>hbay.fun</code> are also implemented for bandwidth selection. 
</p>


<h3>Details</h3>


<dl>
<dt>The estimated density or p.m.f:</dt>
<dd>
<p> The associated kernel estimator <code class="reqn">\widehat{f}_n</code> of  <code class="reqn">f</code> is defined as
</p>
<p style="text-align: center;"><code class="reqn">\widehat{f}_n(x) = \frac{1}{n}\sum_{i=1}^{n}{K_{x,h}(X_i)},</code>
</p>
<p> where <code class="reqn">K_{x,h}</code> is one of the kernels <code>kef</code> defined below.
In practice, we first calculate the global normalizing constant
</p>
<p style="text-align: center;"><code class="reqn">{C}_n =   \int_{x\in T}{\widehat{f}_n(x) \nu(dx)},</code>
</p>
<p> where  <code class="reqn">T</code> is the support of the density or p.m.f. function and <code class="reqn"> \nu</code> is the Lebesgue or count measure on <code class="reqn">T</code>. For both continuous and discrete associated kernels, this normalizing constant is not generally equal to 1 and it will be computed. The represented  density  or p.m.f. estimate is then <code class="reqn">\tilde{f}_n=\widehat{f}_n/C_n</code>. 
</p>
<p>For <b>discrete data</b>, the integrated squared error (ISE) defined by </p>
<p style="text-align: center;"><code class="reqn">{ISE}_0 =   \sum_{x\in N}{{\{\tilde{f}_n(x)} - f_0(x)\}^2}</code>
</p>
<p> is the criteria used to measure the smoothness of the associated kernel estimator <code class="reqn">\tilde{f}_n</code> with the empirical p.m.f. <code class="reqn">f_0</code>; 
see Kokonendji and Senga Kiessé (2011).
</p>
</dd>
</dl>
<dl>
<dt>The estimated regressor:</dt>
<dd>
<p> Both in continuous and discrete cases, considering the relation between a response variable <code class="reqn">y</code> and an explanatory variable <code class="reqn">x</code> given by </p>
<p style="text-align: center;"><code class="reqn">y=m(x)+\epsilon ,</code>
</p>
<p> where <code class="reqn">m</code> is an unknown regession function on <code class="reqn">T</code> and <code class="reqn">\epsilon</code> the disturbance term with null mean and finite variance. Let  <code class="reqn">(x_1,y_1),\ldots,(x_n,y_n)</code> be a sequence of independent and identically distributed (iid) random vectors on <code class="reqn">T\times R</code> with <code class="reqn">m(x)=E(y|x)</code>.
The well-known Nadaraya-Watson estimator using  associated kernels is  <code class="reqn">\widehat{m}_n</code> defined as
</p>
<p style="text-align: center;"><code class="reqn">\widehat{m}_n(x) = \sum_{i=1}^{n}{\omega_{x}(X_i)Y_i},</code>
</p>
<p> where  <code class="reqn">\omega_{x}(X_i)=K_{x,h}(X_i)/\sum_{i=1}^{n}{K_{x,h}(X_i)}</code> and <code class="reqn">K_{x,h}</code> is one of the associated kernels defined below.
</p>
<p>Beside the criterion of kernel support, we retain the root mean squared error (RMSE) and also the practical coefficient of determination <code class="reqn">R^2</code> defined  respectively by
</p>
<p style="text-align: center;"><code class="reqn">RMSE = \sqrt{\frac{1}{n}\sum_{i=1}^{n}{\{y_i-\widehat{m}_n(x_i)\}^2}}</code>
</p>
<p> and
</p>
<p style="text-align: center;"><code class="reqn">R^2=\frac{\sum_{i=1}^{n}{\{\widehat{m}_n(x_i)-\bar{y}\}^2}}{\sum_{i=1}^{n}(y_i-\bar{y})^2},</code>
</p>

<p>where <code class="reqn">\bar{y}=n^{-1}(y_1+\ldots+y_n)</code>; see Kokonendji et al. (2009).
</p>
</dd>
</dl>
<p>Given a data sample, the  package allows to compute the density or p.m.f. and regression functions using one of the seven associated kernels: extended beta, lognormal, gamma, reciprocal inverse Gaussian for continuous data, DiracDU for categorical data, and binomial and discrete triangular for count data. The bandwidth parameter is computed using the cross-validation technique. When the associated kernel function is binomial, the bandwidth parameter is also computed using the local Bayesian procedure. The associated kernel functions  are defined below. The first four kernels are for continuous data and the last three kernels are for discrete case. 
</p>

<dl>
<dt>Extended beta kernel:</dt>
<dd>
<p> The extended beta kernel is defined on <code class="reqn">{S}_{x,h,a,b}=[a,b]=T</code> with <code class="reqn">a&lt;b&lt;\infty</code>, <code class="reqn">x \in T</code> and <code class="reqn">h&gt;0</code>:
</p>
<p style="text-align: center;"><code class="reqn">BE_{x,h,a,b}(y) = \frac {(y-a)^{(x-a)/\{(b-a)h\}}(b-y)^{(b-x)/\{(b-a)h\}}} {(b-a)^{1+h^{-1}}B\left(1+(x-a)/(b-a)h,1+(b-x)/(b-a)h\right)}1_{S_{x,h,a,b}}(y),</code>
</p>

<p>where <code class="reqn">B(r,s)=\int_0^1 t^{r-1}(1-t)^{s-1}dt</code> is the usual beta function with <code class="reqn">r&gt;0</code>, <code class="reqn">s&gt;0</code> and  <code class="reqn">1_A</code> denotes the indicator function of A.  For <code class="reqn">a=0</code> and <code class="reqn">b=1</code>, it corresponds to the beta kernel which is the probability density function of the beta distribution with shape parameters <code class="reqn">1+x/h</code> and <code class="reqn">(1-x)/h</code>; see  Libengué (2013).
</p>
</dd>
<dt>Gamma kernel:</dt>
<dd>
<p> The gamma kernel is defined on <code class="reqn">{S}_{x,h}=[0, \infty)=T</code> with <code class="reqn">x \in T</code> and <code class="reqn">h&gt;0</code> by
</p>
<p style="text-align: center;"><code class="reqn">GA_{x,h}(y) = \frac {y^{x/h}} {\Gamma(1+x/h)h^{1+x/h}}exp\left(-\frac{y}{h} \right)1_{S_{x,h}}(y),</code>
</p>

<p>where  <code class="reqn">\Gamma(z)=\int_0^\infty t^{z-1}e^{-t}dt</code>  is the classical gamma function. The  probability density function <code class="reqn">GA_{x,h}</code> is the gamma distribution with scale parameter <code class="reqn">1+x/h</code> and shape parameter <code class="reqn">h</code>; see Chen (2000).  
</p>
</dd>
<dt>Lognormal kernel:</dt>
<dd>
<p>The lognormal kernel is defined on <code class="reqn">{S}_{x,h}=[0,\infty)=T</code> with <code class="reqn">x \in T</code> and <code class="reqn">h&gt;0</code> by
</p>
<p style="text-align: center;"><code class="reqn">LN_{x,h}(y) = \frac {1} {yh\sqrt{2\pi}}exp\left\{-\frac{1}{2}\left(\frac{1}{h}log(\frac{y}{x})-h \right)^{2}\right\}1_{S_{x,h}}(y).</code>
</p>

<p>It is the probability density function  of the classical lognormal distribution with  parameters <code class="reqn">log(x)+h^{2}</code> and <code class="reqn">h</code>; see Libengué (2013).
</p>
</dd>
<dt>Binomial kernel:</dt>
<dd>
<p> Let <code class="reqn">x\in  N:= \{0, 1, \ldots \}</code> and <code class="reqn">{S}_x = \{0, 1, \ldots, x + 1\}</code>. The Binomial kernel is defined on the support <code class="reqn">{S}_x</code> by
</p>
<p style="text-align: center;"><code class="reqn">B_{x,h}(y) = \frac {(x+1)!} {y!(x+1-y)!}\left(\frac{x+h}{x+1}\right)^y\left(\frac{1-h}{x+1}\right)^{(x+1-y)}1_{S_{x}}(y),</code>
</p>

<p>where <code class="reqn"> h\in(0, 1]</code>. Note that <code class="reqn">B_{x,h}</code> is the p.m.f. of the binomial distribution with its number of trials <code class="reqn"> x+1</code> and its success probability <code class="reqn">(x+h)/(x+1)</code>; see Kokonendji and Senga Kiessé (2011).
</p>
</dd>
<dt>Discrete triangular kernel:</dt>
<dd>
<p> For fixed arm <code class="reqn">a\in  N</code>, we define <code class="reqn">{S}_{x,a} = \{x-a,\ldots, x, \ldots, x + a\}</code>.  The discrete triangular kernel is defined on  <code class="reqn">{S}_{x,a}</code> by
</p>
<p style="text-align: center;"><code class="reqn">DT_{x,h;a}(y) = \frac {(a+1)^h - |y-x|^h} {P(a,h)}1_{S_{x,a}}(y),</code>
</p>

<p>where <code class="reqn">x\in  N</code>,  <code class="reqn">h&gt;0</code> and <code class="reqn">P(a,h)=(2a+1)(a+1)^h - 2(1+2^h+ \cdots +a^h)</code> is the normalizing constant. For <code class="reqn">a=0</code>, the Discrete Triangular kernel <code class="reqn">DT_{x,h;0}</code> corresponds to the Dirac kernel on <code class="reqn">x</code>; see Kokonendji et al. (2007), and also Kokonendji and Zocchi (2010) for an asymmetric version of discrete triangular. 
</p>
</dd>
<dt>DiracDU kernel:</dt>
<dd>
<p> For fixed number of categories <code class="reqn">c\in \{2,3,...\} </code>, we define  <code class="reqn">{S}_{c} = \{0, 1, \ldots, c-1\}</code>. The DiracDU kernel is defined on <code class="reqn">{S}_{c}</code> by 
</p>
<p style="text-align: center;"><code class="reqn">DU_{x,h;c}(y) = (1 - h)1_{\{x\}}(y)+\frac {h} {c-1}1_{S_{c}\setminus\{x\}}(y),</code>
</p>

<p>where <code class="reqn">x\in {S}_{c} </code> and  <code class="reqn"> h\in(0, 1]</code>. See Kokonendji and Senga Kiessé (2011), and also Aitchison and Aitken (1976) for multivariate case.
</p>
</dd>
</dl>
<p>Note that the global normalizing constant is 1 for DiracDU.
</p>
<dl>
<dt>The bandwidth selection:</dt>
<dd>
<p> Two functions are implemented to select the bandwidth: cross-validation and local Bayesian procedure. The cross-validation technique is used for all the associated kernels both in density and regression; see Kokonendji and Senga Kiessé (2011). The local Bayesian procedure is implemented to select the bandwidth in the estimation of p.m.f. when using binomial kernel; see Zougab et al. (2014).
</p>
<p>In the coming versions of the package, adaptive Bayesian procedure will be included for bandwidth selection in density estimation when using gamma kernel. A global Bayesian procedure will also be implemented for bandwidth selection in regression when using binomial kernel. 
</p>
</dd>   
</dl>
<h3>Author(s)</h3>

<p>W. E. Wansouwé, S. M. Somé and C. C. Kokonendji
</p>
<p>Maintainer: W. E. Wansouwé &lt;ericwansouwe@gmail.com&gt;
</p>


<h3>References</h3>

<p>Aitchison, J. and Aitken, C.G.G. (1976). Multivariate binary discrimination by the kernel method, <em>Biometrika</em>  <b>63</b>, 413 - 420.
</p>
<p>Chen, S. X. (1999). Beta kernels estimators for density functions, <em>Computational Statistics and Data Analysis</em>  <b>31</b>,  131 - 145.
</p>
<p>Chen, S. X. (2000). Probability density function estimation using gamma kernels, <em>Annals of the Institute of Statistical Mathematics</em>  <b>52</b>,  471 - 480.
</p>
<p>Igarashi, G. and Kakizawa, Y. (2015). Bias correction for some asymmetric kernel estimators, <em>Journal of Statistical Planning and Inference</em>  <b>159</b>,  37 - 63.
</p>
<p>Kokonendji, C.C. and Senga Kiessé, T. (2011). Discrete associated kernel method and extensions,
<em>Statistical Methodology</em>  <b>8</b>,  497 - 516.
</p>
<p>Kokonendji, C.C., Senga Kiessé, T. and Demétrio, C.G.B. (2009). Appropriate kernel regression on a count explanatory variable and applications,
<em>Advances and Applications in Statistics</em>  <b>12</b>,  99 - 125.
</p>
<p>Libengue, F.G. (2013). <em>Méthode Non-Paramétrique par Noyaux Associés Mixtes et Applications</em>, Ph.D. Thesis Manuscript (in French) to Université  de Franche-Comté, Besançon, France and Université de  Ouagadougou, Burkina Faso, June 2013, <b>LMB no. 14334</b>, Besançon.
</p>
<p>Zougab, N., Adjabi, S. and Kokonendji, C.C. (2014). Bayesian approach in nonparametric count regression with binomial kernel, <em> Communications in Statistics - Simulation and Computation </em>  <b>43</b>, 1052 - 1063.
</p>


</div>